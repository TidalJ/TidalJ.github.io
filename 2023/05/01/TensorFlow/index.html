<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>TensorFlow</title><meta name="description" content="Living in the moment"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Chao Jiang's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article id="page"><h1>TensorFlow</h1><hr> 
<h1><a name="t1"></a><a id="_41"></a>一.白话<a href="https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;神经网络\&quot;}&quot;}" data-tit="神经网络" data-pretit="神经网络">神经网络</a></h1> 
<p>第一部分将简单讲解"莫烦大神"网易云课程对神经网络的介绍，讲得清晰透彻，推荐大家阅读；第二部分将讲述我的理解。开始吧！让我们一起进入神经网络和TensorFlow的世界。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127195143597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p><strong>首先，什么是神经网络（Neural Networks）？</strong><br> 计算机神经网络是一种模仿生物神经网络或动物神经中枢，特别是大脑的结构和功能，它是一种数学模型或计算机模型。神经网络由大量的神经元连接并进行计算，大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应的过程。</p> 
<p>现代神经网络是一种基于传统统计学建模的工具，常用来对输入和输出间复杂的关系进行建模，或探索数据间的模式，神经网络是一种运算模型，有大量的节点或神经元及其联系构成。和人类的神经元一样，它们负责传递信息和加工信息，神经元也能被训练或强化，形成固定的神经形态，对特殊的信息有更强烈的反应。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127195334141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p><strong>神经网络是如何工作的呢？</strong><br> 如上图所示，不管这是一只跳跃飞奔的猫，或是一只静静思考的猫，你都知道它是一只猫，因为你的大脑已经被告知过圆眼睛、毛茸茸、尖耳朵的就是猫，你通过成熟的视觉神经系统判断它是猫。计算机也是一样，通过不断的训练，告诉哪些是猫、哪些是狗、哪些是猪，它们会通过数学模型来概括这些学习的判断，最终以数学的形式（0或1）来分类。目前，谷歌、百度图片搜索都能清晰识别事物，这些都归功于计算机神经系统的飞速发展。</p> 
<p>神经网络系统由多层神经层构成，为了区分不同的神经层，我们分为：</p> 
<ul><li>输入层：直接接收信息的神经层，比如接收一张猫的图片</li><li>输出层：信息在神经元中传递中转和分析权衡，形成输出结果，通过该层输出的结果可以看出计算机对事物的认知</li><li>隐藏层：在输入和输出层之间的众多神经元连接组成的各个层面，可以有多层，负责对传入信息的加工处理，经过多层加工才能衍生出对认知的理解</li></ul> 
<p><img src="https://img-blog.csdnimg.cn/20191127195813911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p><strong>神经网络举例说明</strong><br> 如下图所示，通常来说，计算机处理的东西和人类有所不同，无论是声音、图片还是文字，它们都只能以数字0或1出现在计算机神经网络里。神经网络看到的图片其实都是一堆数字，对数字的加工处理最终生成另一堆数字，并且具有一定认知上的意义，通过一点点的处理能够得知计算机到底判断这张图片是猫还是狗。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127200408932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p><strong>计算机是怎么训练的呢？</strong><br> 首先，需要很多的数据，比如需要计算机判断是猫还是狗，就需要准备上千万张有标记的图片，然后再进行上千万次的训练。计算机通过训练或强化学习判断猫，将获取的特征转换为数学的形式。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127200811475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p>我们需要做的就是只给计算机看图片，然后让它给我们一个不成熟也不准确的答案，有可能100次答案中有10%是正确的。如果给计算机看图片是一张飞奔的猫（如下图），但计算机可能识别成一条狗，尽管它识别错误，但这个错误对计算机是非常有价值的，可以用这次错误的经验作为一名好老师，不断学习经验。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127202223199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p><strong>那么计算机是如何学习经验的呢？</strong><br> 它是通过对比预测答案和真实答案的差别，然后把这种差别再反向传递回去，修改神经元的权重，让每个神经元向正确的方向改动一点点，这样到下次识别时，通过所有改进的神经网络，计算机识别的正确率会有所提高。最终每一次的一点点，累加上千万次的训练，就会朝正确的方向上迈出一大步。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127202401840.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p>最后到验收结果的时候，给计算机再次显示猫的图片时，它就能正确预测这是一只猫。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127202635872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p><strong>激励函数是什么东东？</strong><br> 接着再进一步看看神经网络是怎么训练的。原来在计算机里每一个神经元都有属于它的激励函数（Active Function），我们可以利用这些激励函数给计算机一个刺激行为。当我们第一次给计算机看一只飞奔的猫时，神经网络中只有部分神经元被激活或激励，被激活传递下去的信息是计算机最为重视的信息，也是对输出结果最有价值的信息。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127203147500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p>如果预测的结果是一只狗，所有神经元的参数就会被调整，这时有一些容易被激活的神经元就会变得迟钝，而另一些会变得敏感起来，这就说明了所有神经元参数正在被修改，变得对图片真正重要的信息敏感，从而被改动的参数就能渐渐预测出正确的答案，它就是一只猫。这就是神经网络的加工过程。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127203522349.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<hr> 
<h1><a name="t2"></a><a id="_98"></a>二.神经网络概念梳理</h1> 
<p>前面通过白话文讲述了神经网络之后，接下来我们对神经网络的概念从头再梳理一遍，这也是为后续深入学习奠定基础。</p> 
<p>神经网络(也称人工神经网络，ANN)算法是80年代机器学习界非常流行的算法，不过在90年代中途衰落。现在，携着“深度学习”之势，神经网络重装归来，重新成为最强大的机器学习算法之一。</p> 
<p><img src="https://img-blog.csdn.net/20151103023058400#pic_center" alt="在这里插入图片描述"></p> 
<p>人工神经网络（Artificial Neural Network，缩写ANN），是一种模仿生物神经网络的结构和功能的数学模型或计算模型。神经网络由大量的人工神经元联结进行计算。其来源于生物，故吴老先先讲述了生物神经网络的基础知识，从而进行引入。</p> 
<p><img src="https://img-blog.csdn.net/20151103023724578#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p><strong>神经细胞通过轴突将信号传递给其他的神经细胞，通过树突向各个方向接受信号。</strong><br> 神经细胞利用电-化学过程交换信号。输入信号来自另一些神经细胞。这些神经细胞的轴突末梢（也就是终端）和本神经细胞的树突相遇形成突触（synapse），信号就从树突上的突触进入本细胞。</p> 
<p>信号在大脑中实际怎样传输是一个相当复杂的过程，但就我们而言，重要的是把它看成和现代的计算机一样，利用一系列的0和1来进行操作。就是说，大脑的神经细胞也只有两种状态：兴奋（fire）和不兴奋（即抑制）。</p> 
<p><img src="https://img-blog.csdn.net/20151103024805255#pic_center" alt="在这里插入图片描述" width="400" height="250"></p> 
<p>神经细胞利用一种我们还不知道的方法，把所有从树突突触上进来的信号进行相加，如果全部信号的总和超过某个阈值，就会激发神经细胞进入兴奋（fire）状态，这时就会有一个电信号通过轴突发送出去给其他神经细胞。如果信号总和没有达到阈值，神经细胞就不会兴奋起来。这样的解释有点过分简单化，但已能满足我们的目的。</p> 
<p><img src="https://img-blog.csdn.net/20151103025739605#pic_center" alt="在这里插入图片描述" width="500" height="380"></p> 
<p>由于人脑具有一下几个特点：</p> 
<ul><li><strong>能实现无监督的学习</strong><br> 大脑能够自己进行学习，而不需要导师的监督教导。如果一个神经细胞在一段时间内受到高频率的刺激，则它和输入信号的神经细胞之间的连接强度就会按某种过程改变，使得该神经细胞下一次受到激励时更容易兴奋。</li><li><strong>对损伤有冗余性(tolerance)</strong><br> 大脑即使有很大一部分受到了损伤, 它仍然能够执行复杂的工作。</li><li><strong>处理信息的效率极高</strong><br> 神经细胞之间电-化学信号的传递，与一台数字计算机中CPU的数据传输相比，速度是非常慢的，但因神经细胞采用了并行的工作方式，使得大脑能够同时处理大量的数据。例如，大脑视觉皮层在处理通过我们的视网膜输入的一幅图象信号时，大约只要100ms的时间就能完成，眼睛并发执行。</li><li><strong>善于归纳推广</strong><br> 大脑和数字计算机不同，它极擅长的事情之一就是模式识别，并能根据已熟悉信息进行归纳推广(generlize)。例如，我们能够阅读他人所写的手稿上的文字，即使我们以前从来没见过他所写的东西。</li><li><strong>它是有意识的</strong></li></ul> 
<p><img src="https://img-blog.csdn.net/20151103032002251#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> 
<p>如下图所示，它表示的是一个人工神经细胞。其中：</p> 
<ul><li>输入(Input)</li><li>权重(Weight)：左边五个灰色圆底字母w代表浮点数</li><li>激励函数(Activation Function)：大圆，所有经过权重调整后的输入加起来，形成单个的激励值</li><li>输出(Output)：神经细胞的输出</li></ul> 
<p><img src="https://img-blog.csdnimg.cn/20191128153527248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="400" height="250"></p> 
<p>进入人工神经细胞的每一个input(输入)都与一个权重w相联系，正是这些权重将决定神经网络的整体活跃性。假设权重为-1和1之间的一个随机数，权重可正可负（激发和抑制作用）。当输入信号进入神经细胞时，它们的值将与它们对应的权重相乘，作为图中大圆的输入。如果激励值超过某个阀值（假设阀值为1.0），就会产生一个值为1的信号输出；如果激励值小于阀值1.0，则输出一个0。这是人工神经细胞激励函数的一种最简单的类型。涉及的数学知识如下图所示：</p> 
<p><img src="https://img-blog.csdn.net/20151103033932054#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>如果最后计算的结果激励值大于阈值1.0，则神经细胞就输出1；如果激励值小于阈值则输出0。这和一个生物神经细胞的兴奋状态或抑制状态是等价的。下面图是通过神经网络实现逻辑表达式与运算：（参考NG斯坦福机器学习讲义）</p> 
<p><img src="https://img-blog.csdn.net/20151103034617548#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>可以看到x1和x2变量作为神经网络的输入，当它们取不同的0或1值时，其结果通过sigmod函数计算的值是不同的。它模拟了整个AND运算。</p> 
<p><img src="https://img-blog.csdn.net/20151103035354873#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>该图中神经网络共有三层 ( 注输入层不是神经细胞，神经细胞只有两层 )：<br> <strong>输入层中的每个输入都馈送到了隐藏层，作为该层每一个神经细胞的输入；然后，从隐藏层的每个神经细胞的输出都连到了它下一层（即输出层）的每一个神经细胞。</strong></p> 
<p>注意：<br> 1.图中仅仅画了一个隐藏层，作为前馈网络，一般地可以有任意多个隐藏层。但在对付你将处理的大多数问题时一层通常是足够的。<br> 2.事实上，有一些问题甚至根本不需要任何隐藏单元，你只要把那些输入直接连结到输出神经细胞就行了。<br> 3.每一层实际都可以有任何数目的神经细胞，这完全取决于要解决的问题的复杂性。但神经细胞数目愈多，网络的工作速度也就愈低，网络的规模总是要求保持尽可能的小。</p> 
<p><img src="https://img-blog.csdn.net/20151103040150028#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>神经网络体系创建成功后，它必须接受训练来认出数字4，方法：<br> 1.先把神经网络的所有权重初始化为任意值；<br> 2.再给他一系列输入代表面板不同配置的输入，对每种输入配置，检查它的输出是什么，并调整相应权重；<br> 3.如果我们送给网络的输入模式不是4，则我们知道网络应该输出一个0。因此每个非4字符时，网络权重应进行调整，使得它的输出趋向于0；当代表4的模式输送给网络时，则应把权重调整到使其输出趋向于1；<br> 4.我们可以进一步识别0到9的所有数字或字母，其本质是手写识别的工作原理。<br> 5.最后，网络不单能认识已经训练的笔迹，还显示了它有显著的归纳和推广能力。</p> 
<p>正是这种归纳推广能力，使得神经网络已经成为能够用于无数应用的一种无价的工具，从人脸识别、医学诊断，直到跑马赛的预测，另外还有电脑游戏中的bot（作为游戏角色的机器人）的导航，或者硬件的robot（真正的机器人）的导航。</p> 
<p><img src="https://img-blog.csdn.net/20151103041044137#pic_center" alt="在这里插入图片描述" width="550" height="300"><br> 上图会演示神经网络在图像识别领域的一个著名应用，这个程序叫做LeNet，是一个基于多个隐层构建的神经网络。通过LeNet可以识别多种手写数字，并且达到很高的识别精度与拥有较好的鲁棒性。LeNet的发明人是机器学习的大牛Yann LeCun（目前google）。</p> 
<p>右下方的方形中显示的是输入计算机的图像，方形上方的红色字样“answer”后面显示的是计算机的输出。左边的三条竖直的图像列显示的是神经网络中三个隐藏层的输出，可以看出，随着层次的不断深入，越深的层次处理的细节越低，例如层3基本处理的都已经是线的细节了。</p> 
<p>这种类型的训练称作有监督的学习（supervised learnig），用来训练的数据称为训练集（training set）。调整权重可以采用许多不同的方法。对本类问题最常用的方法就是反向传播（backpropagation，简称backprop或BP）方法，即BP神经网络。</p> 
<p>你自己可以去学习另外的一种训练方式，即根本不需要任何导师来监督的训练，或称无监督学习（unsupervised learnig）。下图是神经网络的简单回顾与总结：</p> 
<p><img src="https://img-blog.csdn.net/20151103042300580#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>最后给大家看一个利用神经网络对图片进行分类的例子：过程就不详细论述了，图片很清晰，对人、汽车、摩托车、卡车进行图片识别，而具体的隐藏层函数需要大家去深入研究，我自己研究得也很浅显，抱歉~</p> 
<p><img src="https://img-blog.csdn.net/20151103042724702#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<hr> 
<h1><a name="t3"></a><a id="TensorFlow_194"></a>三.TensorFlow</h1> 
<h2><a name="t4"></a><a id="1TensorFlow_196"></a>1.TensorFlow简介</h2> 
<p>TensorFlow™是一个基于数据流编程（dataflow programming）的符号数学系统，被广泛应用于各类机器学习（machine learning）算法的编程实现，其前身是谷歌的神经网络算法库DistBelief 。Tensorflow拥有多层级结构，可部署于各类服务器、PC终端和网页并支持GPU和TPU高性能数值计算，被广泛应用于谷歌内部的产品开发和各领域的科学研究 。</p> 
<p>TensorFlow由谷歌人工智能团队谷歌大脑（Google Brain）开发和维护，拥有包括TensorFlow Hub、TensorFlow Lite、TensorFlow Research Cloud在内的多个项目以及各类应用程序接口（Application Programming Interface, API）。</p> 
<p>TensorFlow官网：<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/">https://tensorflow.google.cn/</a></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128160138638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> 
<p>TensorFlow 是一个端到端开源机器学习平台。它拥有一个包含各种工具、库和社区资源的全面灵活生态系统，可以让研究人员推动机器学习领域的先进技术的发展，并让开发者轻松地构建和部署由机器学习提供支持的应用。总之，如果有TensorFlow，我们就可以很自如地玩转神经网络。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191128160239614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128160247489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> 
<hr> 
<h2><a name="t5"></a><a id="2_214"></a>2.安装过程</h2> 
<p>TensorFlow即可以支持CPU，也可以支持CPU+GPU。前者的环境需求简单，后者需要额外的支持。TensorFlow的安装方式很多，包括：</p> 
<ul><li>pip 安装</li><li>virtualenv安装</li><li>docker安装</li><li>从安装源安装</li></ul> 
<p>本文将使用pip安装，pip在每个系统的安装方式包括：</p> 
<ul><li>Linux \ MacOS \ Windows</li><li>CPU版 \ GPU版（GPU版本比CPU版本快很多倍）</li><li>测试版</li><li>更新TensorFlow</li></ul> 
<p>TensorFlow支持Windows用户，由于我的计算机是Windows操作系统，这里使用该方法进行安装，这里安装的环境为：<strong>Windows10+CPU+TensorFlow2.0+Anaconda+Python3.6</strong></p> 
<br> 
<p><strong>第一步：官网下载Anaconda并安装</strong></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128161531571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="300"></p> 
<p><strong>第二步：安装Anaconda之后，打开“Anaconda Prompt”命令行，检查Anaconda是否安装成功及环境</strong></p> 
<pre data-index="0" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token comment">//检查Anaconda是否成功安装</span>
conda <span class="token operator">--</span>version
<span class="token comment">//检测目前安装了哪些环境</span>
conda info <span class="token operator">--</span>envs
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128161709258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> 
<p><strong>第三步：检查当前环境可以安装哪些版本的Python，作者选择Python3.6版本</strong></p> 
<pre data-index="1" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">conda search <span class="token operator">--</span>full<span class="token operator">-</span>name python
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128162414841.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> 
<p>由于作者电脑不支持GPU，所以这里只安装CPU版本，GPU安装推荐下面文章。<br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/wangbowj123/article/details/89381562">tensorflow2.0GPU版本的环境配置与安装教程 normalization</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011119817/article/details/88309256">[Tensorflow2.0] Tensorflow2.0的安装教程 - 牛andmore牛</a></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128162420952.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p><strong>第四步：创建环境，用来安装tensorflow2.0以及相关的python packages</strong></p> 
<pre data-index="2" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">conda create <span class="token operator">-</span>n tf2 python<span class="token operator">=</span><span class="token number">3.6</span>
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128164102712.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128164331680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p><strong>第五步：激活TensorFlow</strong></p> 
<pre data-index="3" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">activate tf2
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128164559459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p><strong>第六步：安装cpu版本TensorFlow</strong></p> 
<pre data-index="4" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">pip install tensorflow<span class="token operator">==</span><span class="token number">2.0</span><span class="token number">.0</span><span class="token operator">-</span>alpha0
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> 
<ul><li>conda search tensorflow #搜CPU版</li><li>conda search tensorflow-gpu #搜GPU版</li><li>conda install tensorflow=2.0.0 #安装CPU版</li><li>conda install tensorflow-gpu=2.0.0 #安装GPU版</li></ul> 
<p><img src="https://img-blog.csdnimg.cn/20191128164710277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128164720358.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p>此时，表示安装结束，接下来开始确认我们是否安装成功。</p> 
<p><strong>第七：打开Anaconda Navigator，选择环境“tf2”，点击spyder下面的“install”。</strong></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128165058698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p>安装好就变成“Launch”了，点击就可以进去了。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191128165155272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="300" height="300"></p> 
<p><strong>第八步：输入代码验证是否安装成功。</strong></p> 
<pre data-index="5" class="prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf 
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128165238554.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p>如果需要退出环境，可以输入下面命令。</p> 
<p><img src="https://img-blog.csdnimg.cn/2019112816535080.png#pic_center" alt="在这里插入图片描述"></p> 
<hr> 
<h2><a name="t6"></a><a id="3_321"></a>3.基础入门</h2> 
<p>最后给出一个简单的实例代码：</p> 
<pre data-index="6" class="set-code-hide prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token triple-quoted-string string">"""
Spyder Editor


<p>This is a temporary script file.</p>
<p>By：Eastmount CSDN YXZ 2019-11-28<br>“””</p>
<p><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf </p>
<p><span class="token comment">#查询TensorFlow版本</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span><strong>version</strong><span class="token punctuation">)</span></p>
<p><span class="token comment">#定义a和b为两个常量</span><br>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">“a”</span><span class="token punctuation">)</span><br>b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">“b”</span><span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span></p>
<p><span class="token comment">#随机生成一个正态分布</span><br>output <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></p>
<p><span class="token comment">#创建2个矩阵并进行相乘</span><br>matrix1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br>matrix2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br>product <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>matrix1<span class="token punctuation">,</span>matrix2<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>matrix1<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>matrix2<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>product<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>product<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></p>
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></span></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li></ul></pre> 
<p>输出结果如下所示：</p> 
<pre data-index="7" class="set-code-hide prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token number">2.0</span><span class="token number">.0</span><span class="token operator">-</span>alpha0

<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span></p>
<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.1826832</span>  <span class="token operator">-</span><span class="token number">0.32986134</span> <span class="token operator">-</span><span class="token number">1.6238695</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.18214056</span>  <span class="token number">0.25923613</span> <span class="token operator">-</span><span class="token number">0.12570491</span><span class="token punctuation">]</span><br> <span class="token punctuation">[</span> <span class="token number">1.0550841</span>  <span class="token operator">-</span><span class="token number">0.6655764</span>  <span class="token operator">-</span><span class="token number">1.5837296</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.10004017</span>  <span class="token number">0.0162886</span>   <span class="token number">0.9483853</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span> <span class="token number">0.4709251</span>  <span class="token operator">-</span><span class="token number">0.18713968</span>  <span class="token number">0.8347026</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span></p>
<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span></p>
<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">12</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">12</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span></p>
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li></ul></pre> 
<hr> 
<h1><a name="t7"></a><a id="_388"></a>四.总结</h1> 
<p>最后希望基础性文章对您有所帮助，作者也是这个领域的菜鸟一枚，希望与您共同进步，后续会继续深入分享Python人工智能系列，如果喜欢点个赞评论，共勉~</p> 
<p><img src="https://img-blog.csdnimg.cn/20191128170443362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="300" height="400"></p> 
<p>中午惊喜收到女神的小蛋糕，下午期末考试，一直忙到凌晨2点，静寂中又涨了一岁。花开蝴蝶自然来，希望自己一直善良下去，品尝到更多幸福的味道。感谢这些年所有帮助和祝福我的人，无以回报，只能去帮助更多的人，分享更好的博客，备好每一次讲台前的课程。忙中带乐，晚安娜，明天接着奋斗~</p> 
<p>(By:Eastmount 2019-11-28 下午4点 <a target="_blank" rel="noopener" href="http://blog.csdn.net/eastmount/">http://blog.csdn.net/eastmount/</a> )</p>
                <div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/Eastmount/article/details/103282042&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-98b95bb57c.css" rel="stylesheet">
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-c216769e99.css" rel="stylesheet">
        ](<div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-25cebea3f9.css">
                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>从本篇文章开始，作者正式开始研究Python<a href="https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;深度学习\&quot;}&quot;}" data-tit="深度学习" data-pretit="深度学习">深度学习</a>、神经网络及人工智能相关知识。第一篇文章主要讲解神经网络基础概念，同时讲解TensorFlow2.0的安装过程及基础用法，主要结合作者之前的博客和"莫烦大神"的视频介绍，后面随着深入会讲解具体的项目及应用。基础性文章，希望对您有所帮助，如果文章中存在错误或不足之处，还请海涵~同时自己也是人工智能的菜鸟，希望大家能与我在这一笔一划的博客中成长起来。</p> 
<p></p> 
<div class="toc"> 
 <h3><a name="t0"></a>文章目录</h3> 
 <ul><li><a href="#_41" target="_self">一.白话神经网络</a></li><li><a href="#_98" target="_self">二.神经网络概念梳理</a></li><li><a href="#TensorFlow_194" target="_self">三.TensorFlow</a></li><li><ul><li><a href="#1TensorFlow_196" target="_self">1.TensorFlow简介</a></li><li><a href="#2_214" target="_self">2.安装过程</a></li><li><a href="#3_321" target="_self">3.基础入门</a></li></ul> 
  </li><li><a href="#_388" target="_self">四.总结</a></li></ul> 
</div> 
<br> 同时推荐前面作者另外三个Python系列文章。从2014年开始，作者主要写了三个Python系列文章，分别是基础知识、网络爬虫和数据分析。2018年陆续增加了Python图像识别和Python人工智能专栏。 
<p></p> 
<ul><li>Python基础知识系列：<a target="_blank" rel="noopener" href="https://blog.csdn.net/eastmount/category_2547623.html">Pythonj基础知识学习与提升</a></li><li>Python网络爬虫系列：<a target="_blank" rel="noopener" href="https://blog.csdn.net/eastmount/category_9264385.html">Python爬虫之Selenium+Phantomjs+CasperJS</a></li><li>Python数据分析系列：<a target="_blank" rel="noopener" href="https://blog.csdn.net/eastmount/category_9265165.html">知识图谱、web数据挖掘及NLP</a></li><li>Python图像识别系列：<a target="_blank" rel="noopener" href="https://blog.csdn.net/eastmount/category_9278090.html">Python图像处理及图像识别</a></li></ul> 
<p><img src="https://img-blog.csdnimg.cn/2019112810131675.png#pic_center" alt="在这里插入图片描述"></p> 
<p>代码下载地址（欢迎大家关注点赞）：</p> 
<ul><li><a target="_blank" rel="noopener" href="https://github.com/eastmountyxz/AI-for-TensorFlow">https://github.com/eastmountyxz/AI-for-TensorFlow</a></li><li><a target="_blank" rel="noopener" href="https://github.com/eastmountyxz/AI-for-Keras">https://github.com/eastmountyxz/AI-for-Keras</a></li></ul> 
<p><strong>作者theano人工智能系列：</strong><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Eastmount/article/details/80363106">[Python人工智能] 一.神经网络入门及theano基础代码讲解</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Eastmount/article/details/80390462">[Python人工智能] 二.theano实现回归神经网络分析</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Eastmount/article/details/80432844">[Python人工智能] 三.theano实现分类神经网络及机器学习基础</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Eastmount/article/details/80499259">[Python人工智能] 四.神经网络和深度学习入门知识</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Eastmount/article/details/80536725">[Python人工智能] 五.theano实现神经网络正规化Regularization处理</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Eastmount/article/details/80650980">[Python人工智能] 六.神经网络的评价指标、特征标准化和特征选择</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Eastmount/article/details/80757556">[Python人工智能] 七.加速神经网络、激励函数和过拟合</a></p> 
<p>参考文献：<br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/eastmount/article/details/49591349">神经网络和机器学习基础入门分享 - 作者的文章</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/abcjennifer/article/details/7758797">Stanford机器学习—第五讲. 神经网络的学习 Neural Networks learning</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/zzwu/article/details/574931">吴祖增前辈：神经网络入门(连载之一)</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/zzwu/article/details/575050">吴祖增前辈：神经网络入门(连载之二)</a><br> 斯坦福机器学习视频NG教授： <a target="_blank" rel="noopener" href="https://class.coursera.org/ml/class/index">https://class.coursera.org/ml/class/index</a><br> 书籍《游戏开发中的人工智能》、《游戏编程中的人工智能技术》<br> 网易云莫烦老师视频（强推）：<a target="_blank" rel="noopener" href="https://study.163.com/course/courseLearn.htm?courseId=1003209007">https://study.163.com/course/courseLearn.htm?courseId=1003209007</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Eppley/article/details/79297503">TensorFlow在Win10上的安装教程和简单示例 - Suffering</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011119817/article/details/88309256">[Tensorflow2.0] Tensorflow2.0的安装教程 - 牛andmore牛</a></p> 
<hr> 
<h1><a name="t1"></a><a id="_41"></a>一.白话<a href="https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;神经网络\&quot;}&quot;}" data-tit="神经网络" data-pretit="神经网络">神经网络</a></h1> 
<p>第一部分将简单讲解"莫烦大神"网易云课程对神经网络的介绍，讲得清晰透彻，推荐大家阅读；第二部分将讲述我的理解。开始吧！让我们一起进入神经网络和TensorFlow的世界。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127195143597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p><strong>首先，什么是神经网络（Neural Networks）？</strong><br> 计算机神经网络是一种模仿生物神经网络或动物神经中枢，特别是大脑的结构和功能，它是一种数学模型或计算机模型。神经网络由大量的神经元连接并进行计算，大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应的过程。</p> 
<p>现代神经网络是一种基于传统统计学建模的工具，常用来对输入和输出间复杂的关系进行建模，或探索数据间的模式，神经网络是一种运算模型，有大量的节点或神经元及其联系构成。和人类的神经元一样，它们负责传递信息和加工信息，神经元也能被训练或强化，形成固定的神经形态，对特殊的信息有更强烈的反应。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127195334141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p><strong>神经网络是如何工作的呢？</strong><br> 如上图所示，不管这是一只跳跃飞奔的猫，或是一只静静思考的猫，你都知道它是一只猫，因为你的大脑已经被告知过圆眼睛、毛茸茸、尖耳朵的就是猫，你通过成熟的视觉神经系统判断它是猫。计算机也是一样，通过不断的训练，告诉哪些是猫、哪些是狗、哪些是猪，它们会通过数学模型来概括这些学习的判断，最终以数学的形式（0或1）来分类。目前，谷歌、百度图片搜索都能清晰识别事物，这些都归功于计算机神经系统的飞速发展。</p> 
<p>神经网络系统由多层神经层构成，为了区分不同的神经层，我们分为：</p> 
<ul><li>输入层：直接接收信息的神经层，比如接收一张猫的图片</li><li>输出层：信息在神经元中传递中转和分析权衡，形成输出结果，通过该层输出的结果可以看出计算机对事物的认知</li><li>隐藏层：在输入和输出层之间的众多神经元连接组成的各个层面，可以有多层，负责对传入信息的加工处理，经过多层加工才能衍生出对认知的理解</li></ul> 
<p><img src="https://img-blog.csdnimg.cn/20191127195813911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p><strong>神经网络举例说明</strong><br> 如下图所示，通常来说，计算机处理的东西和人类有所不同，无论是声音、图片还是文字，它们都只能以数字0或1出现在计算机神经网络里。神经网络看到的图片其实都是一堆数字，对数字的加工处理最终生成另一堆数字，并且具有一定认知上的意义，通过一点点的处理能够得知计算机到底判断这张图片是猫还是狗。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127200408932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p><strong>计算机是怎么训练的呢？</strong><br> 首先，需要很多的数据，比如需要计算机判断是猫还是狗，就需要准备上千万张有标记的图片，然后再进行上千万次的训练。计算机通过训练或强化学习判断猫，将获取的特征转换为数学的形式。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127200811475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> 
<p>我们需要做的就是只给计算机看图片，然后让它给我们一个不成熟也不准确的答案，有可能100次答案中有10%是正确的。如果给计算机看图片是一张飞奔的猫（如下图），但计算机可能识别成一条狗，尽管它识别错误，但这个错误对计算机是非常有价值的，可以用这次错误的经验作为一名好老师，不断学习经验。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127202223199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p><strong>那么计算机是如何学习经验的呢？</strong><br> 它是通过对比预测答案和真实答案的差别，然后把这种差别再反向传递回去，修改神经元的权重，让每个神经元向正确的方向改动一点点，这样到下次识别时，通过所有改进的神经网络，计算机识别的正确率会有所提高。最终每一次的一点点，累加上千万次的训练，就会朝正确的方向上迈出一大步。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127202401840.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p>最后到验收结果的时候，给计算机再次显示猫的图片时，它就能正确预测这是一只猫。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127202635872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p><strong>激励函数是什么东东？</strong><br> 接着再进一步看看神经网络是怎么训练的。原来在计算机里每一个神经元都有属于它的激励函数（Active Function），我们可以利用这些激励函数给计算机一个刺激行为。当我们第一次给计算机看一只飞奔的猫时，神经网络中只有部分神经元被激活或激励，被激活传递下去的信息是计算机最为重视的信息，也是对输出结果最有价值的信息。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127203147500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p>如果预测的结果是一只狗，所有神经元的参数就会被调整，这时有一些容易被激活的神经元就会变得迟钝，而另一些会变得敏感起来，这就说明了所有神经元参数正在被修改，变得对图片真正重要的信息敏感，从而被改动的参数就能渐渐预测出正确的答案，它就是一只猫。这就是神经网络的加工过程。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191127203522349.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<hr> 
<h1><a name="t2"></a><a id="_98"></a>二.神经网络概念梳理</h1> 
<p>前面通过白话文讲述了神经网络之后，接下来我们对神经网络的概念从头再梳理一遍，这也是为后续深入学习奠定基础。</p> 
<p>神经网络(也称人工神经网络，ANN)算法是80年代机器学习界非常流行的算法，不过在90年代中途衰落。现在，携着“深度学习”之势，神经网络重装归来，重新成为最强大的机器学习算法之一。</p> 
<p><img src="https://img-blog.csdn.net/20151103023058400#pic_center" alt="在这里插入图片描述"></p> 
<p>人工神经网络（Artificial Neural Network，缩写ANN），是一种模仿生物神经网络的结构和功能的数学模型或计算模型。神经网络由大量的人工神经元联结进行计算。其来源于生物，故吴老先先讲述了生物神经网络的基础知识，从而进行引入。</p> 
<p><img src="https://img-blog.csdn.net/20151103023724578#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p><strong>神经细胞通过轴突将信号传递给其他的神经细胞，通过树突向各个方向接受信号。</strong><br> 神经细胞利用电-化学过程交换信号。输入信号来自另一些神经细胞。这些神经细胞的轴突末梢（也就是终端）和本神经细胞的树突相遇形成突触（synapse），信号就从树突上的突触进入本细胞。</p> 
<p>信号在大脑中实际怎样传输是一个相当复杂的过程，但就我们而言，重要的是把它看成和现代的计算机一样，利用一系列的0和1来进行操作。就是说，大脑的神经细胞也只有两种状态：兴奋（fire）和不兴奋（即抑制）。</p> 
<p><img src="https://img-blog.csdn.net/20151103024805255#pic_center" alt="在这里插入图片描述" width="400" height="250"></p> 
<p>神经细胞利用一种我们还不知道的方法，把所有从树突突触上进来的信号进行相加，如果全部信号的总和超过某个阈值，就会激发神经细胞进入兴奋（fire）状态，这时就会有一个电信号通过轴突发送出去给其他神经细胞。如果信号总和没有达到阈值，神经细胞就不会兴奋起来。这样的解释有点过分简单化，但已能满足我们的目的。</p> 
<p><img src="https://img-blog.csdn.net/20151103025739605#pic_center" alt="在这里插入图片描述" width="500" height="380"></p> 
<p>由于人脑具有一下几个特点：</p> 
<ul><li><strong>能实现无监督的学习</strong><br> 大脑能够自己进行学习，而不需要导师的监督教导。如果一个神经细胞在一段时间内受到高频率的刺激，则它和输入信号的神经细胞之间的连接强度就会按某种过程改变，使得该神经细胞下一次受到激励时更容易兴奋。</li><li><strong>对损伤有冗余性(tolerance)</strong><br> 大脑即使有很大一部分受到了损伤, 它仍然能够执行复杂的工作。</li><li><strong>处理信息的效率极高</strong><br> 神经细胞之间电-化学信号的传递，与一台数字计算机中CPU的数据传输相比，速度是非常慢的，但因神经细胞采用了并行的工作方式，使得大脑能够同时处理大量的数据。例如，大脑视觉皮层在处理通过我们的视网膜输入的一幅图象信号时，大约只要100ms的时间就能完成，眼睛并发执行。</li><li><strong>善于归纳推广</strong><br> 大脑和数字计算机不同，它极擅长的事情之一就是模式识别，并能根据已熟悉信息进行归纳推广(generlize)。例如，我们能够阅读他人所写的手稿上的文字，即使我们以前从来没见过他所写的东西。</li><li><strong>它是有意识的</strong></li></ul> 
<p><img src="https://img-blog.csdn.net/20151103032002251#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> 
<p>如下图所示，它表示的是一个人工神经细胞。其中：</p> 
<ul><li>输入(Input)</li><li>权重(Weight)：左边五个灰色圆底字母w代表浮点数</li><li>激励函数(Activation Function)：大圆，所有经过权重调整后的输入加起来，形成单个的激励值</li><li>输出(Output)：神经细胞的输出</li></ul> 
<p><img src="https://img-blog.csdnimg.cn/20191128153527248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="400" height="250"></p> 
<p>进入人工神经细胞的每一个input(输入)都与一个权重w相联系，正是这些权重将决定神经网络的整体活跃性。假设权重为-1和1之间的一个随机数，权重可正可负（激发和抑制作用）。当输入信号进入神经细胞时，它们的值将与它们对应的权重相乘，作为图中大圆的输入。如果激励值超过某个阀值（假设阀值为1.0），就会产生一个值为1的信号输出；如果激励值小于阀值1.0，则输出一个0。这是人工神经细胞激励函数的一种最简单的类型。涉及的数学知识如下图所示：</p> 
<p><img src="https://img-blog.csdn.net/20151103033932054#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>如果最后计算的结果激励值大于阈值1.0，则神经细胞就输出1；如果激励值小于阈值则输出0。这和一个生物神经细胞的兴奋状态或抑制状态是等价的。下面图是通过神经网络实现逻辑表达式与运算：（参考NG斯坦福机器学习讲义）</p> 
<p><img src="https://img-blog.csdn.net/20151103034617548#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>可以看到x1和x2变量作为神经网络的输入，当它们取不同的0或1值时，其结果通过sigmod函数计算的值是不同的。它模拟了整个AND运算。</p> 
<p><img src="https://img-blog.csdn.net/20151103035354873#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>该图中神经网络共有三层 ( 注输入层不是神经细胞，神经细胞只有两层 )：<br> <strong>输入层中的每个输入都馈送到了隐藏层，作为该层每一个神经细胞的输入；然后，从隐藏层的每个神经细胞的输出都连到了它下一层（即输出层）的每一个神经细胞。</strong></p> 
<p>注意：<br> 1.图中仅仅画了一个隐藏层，作为前馈网络，一般地可以有任意多个隐藏层。但在对付你将处理的大多数问题时一层通常是足够的。<br> 2.事实上，有一些问题甚至根本不需要任何隐藏单元，你只要把那些输入直接连结到输出神经细胞就行了。<br> 3.每一层实际都可以有任何数目的神经细胞，这完全取决于要解决的问题的复杂性。但神经细胞数目愈多，网络的工作速度也就愈低，网络的规模总是要求保持尽可能的小。</p> 
<p><img src="https://img-blog.csdn.net/20151103040150028#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>神经网络体系创建成功后，它必须接受训练来认出数字4，方法：<br> 1.先把神经网络的所有权重初始化为任意值；<br> 2.再给他一系列输入代表面板不同配置的输入，对每种输入配置，检查它的输出是什么，并调整相应权重；<br> 3.如果我们送给网络的输入模式不是4，则我们知道网络应该输出一个0。因此每个非4字符时，网络权重应进行调整，使得它的输出趋向于0；当代表4的模式输送给网络时，则应把权重调整到使其输出趋向于1；<br> 4.我们可以进一步识别0到9的所有数字或字母，其本质是手写识别的工作原理。<br> 5.最后，网络不单能认识已经训练的笔迹，还显示了它有显著的归纳和推广能力。</p> 
<p>正是这种归纳推广能力，使得神经网络已经成为能够用于无数应用的一种无价的工具，从人脸识别、医学诊断，直到跑马赛的预测，另外还有电脑游戏中的bot（作为游戏角色的机器人）的导航，或者硬件的robot（真正的机器人）的导航。</p> 
<p><img src="https://img-blog.csdn.net/20151103041044137#pic_center" alt="在这里插入图片描述" width="550" height="300"><br> 上图会演示神经网络在图像识别领域的一个著名应用，这个程序叫做LeNet，是一个基于多个隐层构建的神经网络。通过LeNet可以识别多种手写数字，并且达到很高的识别精度与拥有较好的鲁棒性。LeNet的发明人是机器学习的大牛Yann LeCun（目前google）。</p> 
<p>右下方的方形中显示的是输入计算机的图像，方形上方的红色字样“answer”后面显示的是计算机的输出。左边的三条竖直的图像列显示的是神经网络中三个隐藏层的输出，可以看出，随着层次的不断深入，越深的层次处理的细节越低，例如层3基本处理的都已经是线的细节了。</p> 
<p>这种类型的训练称作有监督的学习（supervised learnig），用来训练的数据称为训练集（training set）。调整权重可以采用许多不同的方法。对本类问题最常用的方法就是反向传播（backpropagation，简称backprop或BP）方法，即BP神经网络。</p> 
<p>你自己可以去学习另外的一种训练方式，即根本不需要任何导师来监督的训练，或称无监督学习（unsupervised learnig）。下图是神经网络的简单回顾与总结：</p> 
<p><img src="https://img-blog.csdn.net/20151103042300580#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p>最后给大家看一个利用神经网络对图片进行分类的例子：过程就不详细论述了，图片很清晰，对人、汽车、摩托车、卡车进行图片识别，而具体的隐藏层函数需要大家去深入研究，我自己研究得也很浅显，抱歉~</p> 
<p><img src="https://img-blog.csdn.net/20151103042724702#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<hr> 
<h1><a name="t3"></a><a id="TensorFlow_194"></a>三.TensorFlow</h1> 
<h2><a name="t4"></a><a id="1TensorFlow_196"></a>1.TensorFlow简介</h2> 
<p>TensorFlow™是一个基于数据流编程（dataflow programming）的符号数学系统，被广泛应用于各类机器学习（machine learning）算法的编程实现，其前身是谷歌的神经网络算法库DistBelief 。Tensorflow拥有多层级结构，可部署于各类服务器、PC终端和网页并支持GPU和TPU高性能数值计算，被广泛应用于谷歌内部的产品开发和各领域的科学研究 。</p> 
<p>TensorFlow由谷歌人工智能团队谷歌大脑（Google Brain）开发和维护，拥有包括TensorFlow Hub、TensorFlow Lite、TensorFlow Research Cloud在内的多个项目以及各类应用程序接口（Application Programming Interface, API）。</p> 
<p>TensorFlow官网：<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/">https://tensorflow.google.cn/</a></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128160138638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> 
<p>TensorFlow 是一个端到端开源机器学习平台。它拥有一个包含各种工具、库和社区资源的全面灵活生态系统，可以让研究人员推动机器学习领域的先进技术的发展，并让开发者轻松地构建和部署由机器学习提供支持的应用。总之，如果有TensorFlow，我们就可以很自如地玩转神经网络。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191128160239614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128160247489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> 
<hr> 
<h2><a name="t5"></a><a id="2_214"></a>2.安装过程</h2> 
<p>TensorFlow即可以支持CPU，也可以支持CPU+GPU。前者的环境需求简单，后者需要额外的支持。TensorFlow的安装方式很多，包括：</p> 
<ul><li>pip 安装</li><li>virtualenv安装</li><li>docker安装</li><li>从安装源安装</li></ul> 
<p>本文将使用pip安装，pip在每个系统的安装方式包括：</p> 
<ul><li>Linux \ MacOS \ Windows</li><li>CPU版 \ GPU版（GPU版本比CPU版本快很多倍）</li><li>测试版</li><li>更新TensorFlow</li></ul> 
<p>TensorFlow支持Windows用户，由于我的计算机是Windows操作系统，这里使用该方法进行安装，这里安装的环境为：<strong>Windows10+CPU+TensorFlow2.0+Anaconda+Python3.6</strong></p> 
<br> 
<p><strong>第一步：官网下载Anaconda并安装</strong></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128161531571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="300"></p> 
<p><strong>第二步：安装Anaconda之后，打开“Anaconda Prompt”命令行，检查Anaconda是否安装成功及环境</strong></p> 
<pre data-index="0" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token comment">//检查Anaconda是否成功安装</span>
conda <span class="token operator">--</span>version
<span class="token comment">//检测目前安装了哪些环境</span>
conda info <span class="token operator">--</span>envs
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128161709258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> 
<p><strong>第三步：检查当前环境可以安装哪些版本的Python，作者选择Python3.6版本</strong></p> 
<pre data-index="1" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">conda search <span class="token operator">--</span>full<span class="token operator">-</span>name python
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128162414841.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> 
<p>由于作者电脑不支持GPU，所以这里只安装CPU版本，GPU安装推荐下面文章。<br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/wangbowj123/article/details/89381562">tensorflow2.0GPU版本的环境配置与安装教程 normalization</a><br> <a target="_blank" rel="noopener" href="https://blog.csdn.net/u011119817/article/details/88309256">[Tensorflow2.0] Tensorflow2.0的安装教程 - 牛andmore牛</a></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128162420952.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> 
<p><strong>第四步：创建环境，用来安装tensorflow2.0以及相关的python packages</strong></p> 
<pre data-index="2" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">conda create <span class="token operator">-</span>n tf2 python<span class="token operator">=</span><span class="token number">3.6</span>
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128164102712.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128164331680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p><strong>第五步：激活TensorFlow</strong></p> 
<pre data-index="3" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">activate tf2
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128164559459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p><strong>第六步：安装cpu版本TensorFlow</strong></p> 
<pre data-index="4" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">pip install tensorflow<span class="token operator">==</span><span class="token number">2.0</span><span class="token number">.0</span><span class="token operator">-</span>alpha0
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> 
<ul><li>conda search tensorflow #搜CPU版</li><li>conda search tensorflow-gpu #搜GPU版</li><li>conda install tensorflow=2.0.0 #安装CPU版</li><li>conda install tensorflow-gpu=2.0.0 #安装GPU版</li></ul> 
<p><img src="https://img-blog.csdnimg.cn/20191128164710277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128164720358.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p>此时，表示安装结束，接下来开始确认我们是否安装成功。</p> 
<p><strong>第七：打开Anaconda Navigator，选择环境“tf2”，点击spyder下面的“install”。</strong></p> 
<p><img src="https://img-blog.csdnimg.cn/20191128165058698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p>安装好就变成“Launch”了，点击就可以进去了。</p> 
<p><img src="https://img-blog.csdnimg.cn/20191128165155272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="300" height="300"></p> 
<p><strong>第八步：输入代码验证是否安装成功。</strong></p> 
<pre data-index="5" class="prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf 
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li></ul></pre> 
<p><img src="https://img-blog.csdnimg.cn/20191128165238554.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> 
<p>如果需要退出环境，可以输入下面命令。</p> 
<p><img src="https://img-blog.csdnimg.cn/2019112816535080.png#pic_center" alt="在这里插入图片描述"></p> 
<hr> 
<h2><a name="t6"></a><a id="3_321"></a>3.基础入门</h2> 
<p>最后给出一个简单的实例代码：</p> 
<pre data-index="6" class="set-code-hide prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token triple-quoted-string string">"""
Spyder Editor

<p>This is a temporary script file.</p>
<p>By：Eastmount CSDN YXZ 2019-11-28<br>“””</p>
<p><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf </p>
<p><span class="token comment">#查询TensorFlow版本</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span><strong>version</strong><span class="token punctuation">)</span></p>
<p><span class="token comment">#定义a和b为两个常量</span><br>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">“a”</span><span class="token punctuation">)</span><br>b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">“b”</span><span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span></p>
<p><span class="token comment">#随机生成一个正态分布</span><br>output <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></p>
<p><span class="token comment">#创建2个矩阵并进行相乘</span><br>matrix1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br>matrix2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br>product <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>matrix1<span class="token punctuation">,</span>matrix2<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>matrix1<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>matrix2<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>product<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>product<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></p>
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></span></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li></ul></pre> 
<p>输出结果如下所示：</p> 
<pre data-index="7" class="set-code-hide prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token number">2.0</span><span class="token number">.0</span><span class="token operator">-</span>alpha0

<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span></p>
<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.1826832</span>  <span class="token operator">-</span><span class="token number">0.32986134</span> <span class="token operator">-</span><span class="token number">1.6238695</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.18214056</span>  <span class="token number">0.25923613</span> <span class="token operator">-</span><span class="token number">0.12570491</span><span class="token punctuation">]</span><br> <span class="token punctuation">[</span> <span class="token number">1.0550841</span>  <span class="token operator">-</span><span class="token number">0.6655764</span>  <span class="token operator">-</span><span class="token number">1.5837296</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.10004017</span>  <span class="token number">0.0162886</span>   <span class="token number">0.9483853</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span> <span class="token number">0.4709251</span>  <span class="token operator">-</span><span class="token number">0.18713968</span>  <span class="token number">0.8347026</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span></p>
<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span></p>
<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">12</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">12</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span></p>
<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li></ul></pre> 
<hr> 
<h1><a name="t7"></a><a id="_388"></a>四.总结</h1> 
<p>最后希望基础性文章对您有所帮助，作者也是这个领域的菜鸟一枚，希望与您共同进步，后续会继续深入分享Python人工智能系列，如果喜欢点个赞评论，共勉~</p> 
<p><img src="https://img-blog.csdnimg.cn/20191128170443362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="300" height="400"></p> 


</div></div></article><div id="paginator"></div></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/TidalJ"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com/tidaljay727/"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><a title="linkedin" target="_blank" rel="noopener nofollow" href="//www.linkedin.com/in/chaojiang777/"><i class="iconfont icon-linkedin"></i></a><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com/profile.php?id=100049727556677"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> Chao Jiang 2023</span></p></footer></body></html>