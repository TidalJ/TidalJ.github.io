<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Vu2 and Vue3</title>
      <link href="/2023/08/01/Vu2-and-Vue3/"/>
      <url>/2023/08/01/Vu2-and-Vue3/</url>
      
        <content type="html"><![CDATA[<h1><a name="t1"></a>vue2 vs <a href="https://so.csdn.net/so/search?q=vue3&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=vue3&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;vue3\&quot;}&quot;}" data-tit="vue3" data-pretit="vue3">vue3</a></h1> <div class="table-box"><table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>对比</td><td>vue2</td><td>vue3</td></tr><tr><td>脚手架</td><td>命令式</td><td>可视化创建脚⼿架</td></tr><tr><td>组件通信</td><td>见下文</td><td>见下文</td></tr><tr><td>数据监听</td><td>watch,computed</td><td>watch,watchEffect,computed</td></tr><tr><td>双向绑定</td><td>Object.defineProperty</td><td>ProxyAPI</td></tr><tr><td></td><td>见下文</td><td>见下文</td></tr><tr><td>api</td><td>选项式</td><td>组合式</td></tr><tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr></tbody></table></div> <h1><a name="t2"></a>双向绑定更新</h1> <p><strong>vue2</strong> 的<a href="https://so.csdn.net/so/search?q=%E5%8F%8C%E5%90%91%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E5%8F%8C%E5%90%91%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;双向数据绑定\&quot;}&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E5%8F%8C%E5%90%91%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;双向数据绑定\&quot;}&quot;}" data-tit="双向数据绑定" data-pretit="双向数据绑定">双向数据绑定</a>是利⽤ES5 的⼀个 API ，Object.defineProperty()对数据进⾏劫持 结合 发布订阅模式的⽅式来实现的。</p> <p><strong>vue3</strong> 中使⽤了 ES6 的 ProxyAPI 对数据代理，通过 reactive() 函数给每⼀个对象都包⼀层 Proxy，通过 Proxy 监听属性的变化，从⽽ 实现对数据的监控。</p> <blockquote>  <p>这⾥是相⽐于vue2版本，使⽤proxy的优势如下</p>  <p>1.<strong>defineProperty只能监听某个属性</strong>，不能对全对象监听 可以省去for in、闭包等内容来提升效率（直接绑定整个对象即可）</p>  <p>2.<strong>可以监听数组，不⽤再去单独的对数组做特异性操作</strong>,通过Proxy可以直接拦截所有对象类型数据的操作，完美⽀持对数组的监听。</p> </blockquote> <h1><a name="t3"></a>实例化</h1> <p>Vue2.x中new出的实例对象，所有的东西都在这个vue对象上，这样其实⽆论你⽤到还是没⽤到，都会跑⼀遍，这样不仅提⾼了性能消耗，也⽆疑增加了⽤户加载时间。</p> <p>⽽vue3.0中可以⽤ES module imports按需引⼊，如：keep-alive内置组件、v-model指令，等等，不仅我们开发起来更加的便捷，减少 了内存消耗，也同时减少了⽤户加载时间，优化⽤户体验。</p> <h1><a name="t5"></a><br> 获取props</h1> <p>vue2在script代码块可以直接获取props，vue3通过setup指令传递</p> <pre data-index="0"><code class="hljs language-typescript"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vue2：<span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(‘props’,<span class="hljs-variable language_">this</span>.<span class="hljs-property">xxx</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vue3：<span class="hljs-title function_">setup</span>(<span class="hljs-params">props,context</span>){ <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(‘props’,props) }</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}" onclick="hljs.signin(event)"></div></pre> <h1><a name="t6"></a>数据和方法的定义</h1> <p>Vue2使⽤的是选项类型API（Options API），Vue3使⽤的是合成型API（Composition API）</p> <p>Vue2：</p> <pre data-index="1"><code class="hljs language-haskell"><span class="hljs-class"><span class="hljs-keyword">data</span>() { <span class="hljs-title">return</span> {}; }, methods:{ }</span></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}" onclick="hljs.signin(event)"></div></pre> <p>Vue3：</p> <p>数据和⽅法都定义在setup中，并统⼀进⾏return{}</p> <h1><a name="t7"></a>给父组件传值emit</h1> <pre data-index="2"><code class="hljs language-scss"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vue2：this.<span class="hljs-variable">$emit</span>()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vue3：<span class="hljs-built_in">setup</span>(props,context){context<span class="hljs-selector-class">.emit</span>()}</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}" onclick="hljs.signin(event)"></div></pre> <h1><a name="t8"></a>&nbsp;watchEffect</h1> <p>Vue3中除了watch，还引入了副作用监听函数watchEffect，用过之后我发现它和React中的useEffect很像，只不过watchEffect不需要传入依赖项。</p> <p>那么什么是watchEffect呢？</p> <p>watchEffect它会立即执行传入的一个函数，同时响应式追踪其依赖，并在其依赖变更时重新运行该函数。</p> <p>computed和watch所依赖的数据必须是响应式的。Vue3引入了watchEffect,watchEffect 相当于将 watch 的依赖源和回调函数合并，当任何你有用到的响应式依赖更新时，该回调函数便会重新执行。不同于 watch的是watchEffect的回调函数会被立即执行，即（{ immediate: true }）。</p> <h1><a name="t9"></a>组件通信</h1> <h2><a name="t10"></a>注意</h2> <p>props中数据流是单项的，即子组件不可改变父组件传来的值</p> <p>在组合式API中，如果想在子组件中用其它变量接收props的值时需要使用toRef将props中的属性转为响应式。</p> <h3><a name="t11"></a>attrs和listeners</h3> <p>子组件使用$attrs可以获得父组件除了props传递的属性和特性绑定属性 (class和 style)之外的所有属性。</p> <p>子组件使用$listeners可以获得父组件(不含.native修饰器的)所有v-on事件监听器，在Vue3中已经不再使用；但是Vue3中的attrs不仅可以获得父组件传来的属性也可以获得父组件v-on事件监听器</p> <h1><a name="t12"></a>路由</h1> <p>vue3和vue2路由常用功能只是写法上有些区别：</p> <p><code>vue3的beforeRouteEnter</code>作为路由守卫的示例是因为它在<code>setup</code>语法糖中是无法使用的；大家都知道<code>setup</code>中组件实例已经创建，是能够获取到组件实例的。而<code>beforeRouteEnter</code>是再进入路由前触发的，此时组件还未创建，所以是无法用在<code>setup</code>中的；如果想在setup语法糖中使用则需要再写一个<code>script</code> 如下：</p> <pre data-index="3"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-operator">&lt;</span>script<span class="hljs-operator">&gt;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">export <span class="hljs-keyword">default</span> {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  beforeRouteEnter(<span class="hljs-keyword">to</span>, <span class="hljs-keyword">from</span>, <span class="hljs-keyword">next</span>) {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> 在渲染该组件的对应路由被 confirm 前调用</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">next</span>()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  },</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">};</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-operator">&lt;</span><span class="hljs-operator">/</span>script<span class="hljs-operator">&gt;</span></div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}" onclick="hljs.signin(event)"></div></pre> <p>vue3路由写法：</p> <pre data-index="4" class="set-code-hide" name="code"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-operator">&lt;</span>script<span class="hljs-operator">&gt;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">import { defineComponent } <span class="hljs-keyword">from</span> <span class="hljs-string">'vue'</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">import { useRoute, useRouter } <span class="hljs-keyword">from</span> <span class="hljs-string">'vue-router'</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">export <span class="hljs-keyword">default</span> defineComponent({</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  beforeRouteEnter (<span class="hljs-keyword">to</span>, <span class="hljs-keyword">from</span>, <span class="hljs-keyword">next</span>) {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> 在渲染该组件的对应路由被 confirm 前调用</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">next</span>()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  },</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  beforeRouteLeave ((<span class="hljs-keyword">to</span>, <span class="hljs-keyword">from</span>, <span class="hljs-keyword">next</span>)<span class="hljs-operator">=</span><span class="hljs-operator">&gt;</span>{<span class="hljs-operator">/</span><span class="hljs-operator">/</span>离开当前的组件，触发</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">next</span>()       </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  }),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  beforeRouteLeave((<span class="hljs-keyword">to</span>, <span class="hljs-keyword">from</span>, <span class="hljs-keyword">next</span>)<span class="hljs-operator">=</span><span class="hljs-operator">&gt;</span>{<span class="hljs-operator">/</span><span class="hljs-operator">/</span>离开当前的组件，触发</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">next</span>()      </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  }),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  setup() {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    const router <span class="hljs-operator">=</span> useRouter()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    const route <span class="hljs-operator">=</span> useRoute()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    const toPage <span class="hljs-operator">=</span> () <span class="hljs-operator">=</span><span class="hljs-operator">&gt;</span> {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">      router.push(xxx)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    }</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-operator">/</span><span class="hljs-operator">/</span>获取params 注意是route</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    route.params</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-operator">/</span><span class="hljs-operator">/</span>获取query</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    route.query</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">      toPage</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    }</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  },</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">});</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-operator">&lt;</span><span class="hljs-operator">/</span>script<span class="hljs-operator">&gt;</span></div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"></span></div><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}" onclick="hljs.signin(event)"></div></pre> <p>vue2写法：</p> <pre data-index="5" class="set-code-hide" name="code"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-operator">&lt;</span>script<span class="hljs-operator">&gt;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">export <span class="hljs-keyword">default</span> {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  beforeRouteEnter (<span class="hljs-keyword">to</span>, <span class="hljs-keyword">from</span>, <span class="hljs-keyword">next</span>) {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> 在渲染该组件的对应路由被 confirm 前调用</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">next</span>()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  },</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  beforeRouteEnter (<span class="hljs-keyword">to</span>, <span class="hljs-keyword">from</span>, <span class="hljs-keyword">next</span>) {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> 在渲染该组件的对应路由被 confirm 前调用</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">next</span>()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  },</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  beforeRouteLeave ((<span class="hljs-keyword">to</span>, <span class="hljs-keyword">from</span>, <span class="hljs-keyword">next</span>)<span class="hljs-operator">=</span><span class="hljs-operator">&gt;</span>{<span class="hljs-operator">/</span><span class="hljs-operator">/</span>离开当前的组件，触发</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">next</span>()       </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  }),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  beforeRouteLeave((<span class="hljs-keyword">to</span>, <span class="hljs-keyword">from</span>, <span class="hljs-keyword">next</span>)<span class="hljs-operator">=</span><span class="hljs-operator">&gt;</span>{<span class="hljs-operator">/</span><span class="hljs-operator">/</span>离开当前的组件，触发</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">next</span>()      </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  }),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  methods:{</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    toPage(){</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">      <span class="hljs-operator">/</span><span class="hljs-operator">/</span>路由跳转</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">      this.$router.push(xxx)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    }</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  },</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  created(){</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-operator">/</span><span class="hljs-operator">/</span>获取params</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    this.$route.params</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-operator">/</span><span class="hljs-operator">/</span>获取query</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    this.$route.query</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  }</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-operator">&lt;</span><span class="hljs-operator">/</span>script<span class="hljs-operator">&gt;</span></div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"></span></div><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}" onclick="hljs.signin(event)"></div></pre> <h1><a name="t13"></a>&nbsp;总结</h1> <p>vue2和vue3比较还是有很多不一样的地方，比如setup语法糖的形式最为便捷而且更符合开发者习惯，未来vue3将会大面积使用这种规则，这样更加符合开发习惯和降低后续维护的成本～</p> ]]></content>
      
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Computer Vision</title>
      <link href="/2023/06/07/Computer%20Vision/"/>
      <url>/2023/06/07/Computer%20Vision/</url>
      
        <content type="html"><![CDATA[<h1>Computer Vision Basics</h1> <h4>1. 图像分割</h4> <p><span style="font-size:18px">&nbsp; &nbsp;&nbsp;从图像中将某个特定区域与其他部分进行分离并提取出来的处理就是图像分割。因为图像分割处理实际上就是区分图像中的“前景目标”和“背景”，所以通常又称之为图像的二值化处理。图像分割在图像分析、图像识别、图像检测等方面占有非常重要的低位。</span></p> <p><span style="font-size:18px">&nbsp; &nbsp;&nbsp;在计算机视觉领域，图像分割（Segmentation）指的是将数字图像细分为多个图像子区域（像素的集合）（也被称作<span style="color:#ff0000">超像素</span>）的过程。图像分割的目的是简化或改变图像的表示形式，使得图像更容易理解和分析。图像分割通常用于定位图像中的物体和边界（线，曲线等）</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; <span style="color:#3333ff">更精确的，图像分割是对图像中的每个像素加标签的一个过程，这一过程使得具有相同标签的像素具有某种共同视觉特性。图像分割的结果是图像上子区域的集合（这些子区域的全体覆盖了整个图像），或是从图像中提取的轮廓线的集合（例如边缘检测）。一个子区域中的每个像素在某种特性的度量下或是由计算得出的特性都是相似的，例如颜色、亮度、纹理。邻接区域在某种特性的度量下有很大的不同。</span><br> </span></p> <p><span style="font-size:18px">&nbsp; &nbsp;&nbsp;在图像分割的处理中，其实可以将图像视作是由像素组成的有序集合，而图像分割就是将此集合按照某种规则划分出若干子集的过程。</span></p> <p class="reader-word-layer reader-word-s10-9" style=""><span style="font-size:18px">&nbsp; &nbsp; 在图像分割的处理中，其实可以将图像视作是由像素组成的有序集合，而图像分割就是将此集合按照某种规则划分出若干子集的过程。</span></p> <p class="reader-word-layer reader-word-s10-9" style=""><span style="font-size:18px">&nbsp; &nbsp; 图像分割的方法依照分割时所依据的图像特征不同，大致可以分为三大类：</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; 1）阈值方法：这种方法是根据图像的灰度值分布特性来确定某个阈值来进行图像分割；</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; 2）边界分割法：这种方法是通过检测出封闭某个区域的边界来进行图像分割的。通俗的讲，这类方法实际上就是沿着闭合的边缘线将其包围的区域剪切出来；</span></p> <p><span style="font-size:18px">&nbsp; &nbsp;3）区域提取方法：这类方法的特点是根据特定区域与其他背景区域特性上的不同来进行图像分割。</span></p> <h1><a name="t1"></a><span style="font-size:18px">2.&nbsp;<span style="font-size:18px">欧氏距离(&nbsp;Euclidean Distance)</span></span></h1> <p><span style="font-size:18px">&nbsp; &nbsp;&nbsp;</span><span style="font-size:18px">通常我们总是习惯在相应的起点和终点之间用直线段相连, 并求取相应的直线距离, 即欧氏距离。</span></p> <p><span style="font-size:18px">&nbsp; &nbsp;&nbsp;但是, 这种方法并非对所有的情况都有效, 当两点间的直线段有一部分不落在所考虑的区域之内时(如小船在湖泊中航行的例子), 欧氏距离对所讨论的问题实际上是没有意义的, 这就是欧距离在 空间分析过程中的局限性。其原因在于定义区域中两点间的距离时, 没有考虑到区域的连通性, 只考虑了起点和终点间的抽象距离。</span></p> <h1><a name="t2"></a><span style="font-size:18px"><span style="font-size:18px">3.&nbsp;</span><span style="font-size:18px">测地距离(G</span><span style="font-size:18px">eodesic Distance)</span></span></h1> <p><span style="font-size:18px"><span style="font-size:18px">&nbsp; &nbsp;&nbsp;测地距离是数学形态学中的一个重要概念，主要用于流域分割（流域又称集水区域，是指流经其中的水流和其它物质从一个公共的出水口排出从而形 成一个集中的排水区域）。</span></span></p> <p><span style="font-size:18px"><span style="font-size:18px">&nbsp; &nbsp;&nbsp;如下图一连通图形所示，A、B是其中两点，按通常欧式距离（ Euclidean distance）也称欧几里得距离，它是一个通常采用的距离定义，它是在m维空间中两个点之间的真实距离）的定义，A、B间的距离应为直线段AB的长度，但是有时线段AB的一部分可能会不包括在连通图形X内，如在下图中线段AB就有一段没有包含在连通的图形中，因此这种距离有其不合理的一面。现用如下方法重新定义A、B之间的距离：由于下图是连通的，故在所给图一的连通图形中至少有一条线路可以连接A、B两点，如下图一所示，所有这些线中最短的一条称为A、B间的测地弧。测地弧的长度称为A、B间的测地距离，记为D(A-B)。</span></span></p> <p><span style="font-size:18px"><span style="font-size:18px">&nbsp; &nbsp;&nbsp;<img src="https://img-blog.csdn.net/20160517103819661" alt=""></span></span></p> <h1><a name="t3"></a><span style="font-size:18px">4.&nbsp;<span style="font-size:18px">SIFT特征</span></span></h1> <p><span style="font-size:18px">&nbsp; &nbsp;&nbsp;&nbsp; SIFT（Scale-invariant feature transform）：尺度不变特征变换，是用于图像处理领域的一种描述。这种描述具有尺度不变性，可在图像中检测出关键点，是一种局部特征描述子。<br> &nbsp; &nbsp; &nbsp; SIFT特征是基于物体上的一些局部外观的<span style="color:#ff0000">兴趣点而与影像的大小和旋转无关</span>。对于光线、噪声、微视角改变的容忍度也相当高。基于这些特性，它们是高度显著而且相对容易撷取，在母数庞大的特征数据库中，很容易辨识物体而且鲜有误认。使用SIFT特征描述对于部分物体遮蔽的侦测率也相当高，甚至只需要3个以上的SIFT物体特征就足以计算出位置与方位。在现今的电脑硬件速度下和小型的特征数据库条件下，辨识速度可接近即时运算。SIFT特征的信息量大，适合在海量数据库中快速准确匹配。</span></p> <p></p> <h2><a name="t4"></a><span style="font-size:18px">4.1 SIFT算法的特点</span></h2> <p><span style="font-size:18px">&amp;nbsp; &amp;nbsp; &amp;nbsp;SIFT算法具有如下一些特点：<br> &amp;nbsp; &amp;nbsp; &amp;nbsp;1）SIFT特征是图像的局部特征，其对<span style="color:#3333ff">旋转、尺度缩放、亮度变化</span><span style="color:#3366ff">保持不变性</span>，对视角变化、仿射变换、噪声也保持一定程度的稳定性；<br> <span style="font-size:18px">&amp;nbsp; &amp;nbsp; &amp;nbsp;</span>2）独特性（Distinctiveness）好：信息量丰富，适用于在海量特征数据库中进行快速、准确的匹配；<br> <span style="font-size:18px">&amp;nbsp; &amp;nbsp; &amp;nbsp;</span>3）多量性：即使少数的几个物体也可以产生大量的SIFT特征向量；<br> <span style="font-size:18px">&amp;nbsp; &amp;nbsp; &amp;nbsp;</span>4）高速性：经优化的SIFT匹配算法甚至可以达到实时的要求；<br> <span style="font-size:18px">&amp;nbsp; &amp;nbsp; &amp;nbsp;</span>5）可扩展性：可以很方便的与其他形式的特征向量进行联合。<br> </span> </p><p></p> <p></p> <h2><a name="t5"></a><span style="font-size:18px">4.2&nbsp;SIFT特征检测编辑</span></h2> <span style="font-size:18px">&nbsp; &nbsp; SIFT特征检测主要包括以下4个基本步骤：<br> &nbsp; &nbsp; 1）尺度空间极值检测<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 搜索所有尺度上的图像位置。通过高斯微分函数来识别潜在的对于尺度和旋转不变的兴趣点。<br> <span style="font-size:18px">&nbsp; &nbsp;&nbsp;</span>2）关键点定位<br> <span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span>在每个候选的位置上，通过一个拟合精细的模型来确定位置和尺度。关键点的选择依据于它们的稳定程度。<br> <span style="font-size:18px">&nbsp; &nbsp;&nbsp;</span>3）方向确定<br> <span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span>基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而提供对于这些变换的不变性。<br> <span style="font-size:18px">&nbsp; &nbsp;&nbsp;</span>4）关键点描述<br> <span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span>在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变化。</span> <p></p> <p></p> <h2><a name="t6"></a><span style="font-size:18px">4.3&nbsp;SIFT特征匹配</span></h2> <span style="font-size:18px">&nbsp; &nbsp; &nbsp;SIFT特征匹配主要包括2个阶段：<br> &nbsp; &nbsp; &nbsp;第一阶段：SIFT特征的生成，即从多幅图像中提取对尺度缩放、旋转、亮度变化无关的特征向量。<br> &nbsp; &nbsp; &nbsp;第二阶段：SIFT特征向量的匹配。<br> &nbsp;&nbsp;</span> <p></p> <h1><a name="t7"></a><span style="font-size:18px">5.&nbsp;BOW (bag of words) 词袋模型</span></h1> <p><span style="font-size:18px">&nbsp; &nbsp;&nbsp;SIFT特征虽然也能描述一幅图像，但是每个SIFT矢量都是128维的，而且一幅图像通常都包含成百上千个SIFT矢量，在进行相似度计算时，这个计算量是非常大的，通行的做法是用聚类算法(如K-means)对这些矢量数据进行聚类，然后用聚类中的一个簇代表BOW中的一个<span style="color:#ff0000">视觉词</span>，将同一幅图像的SIFT矢量映射到视觉词序列生成码本，这样每一幅图像只用一个<span style="color:#ff0000">码本矢量</span>来描述，这样计算相似度时效率就大大提高了。</span></p> <p></p> <h1><a name="t8"></a><span style="font-size:18px">6.&nbsp;Haar-like特征</span></h1> <span style="font-size:18px">&nbsp; &nbsp; Haar-like特征：Haar特征值反映了图像的灰度变化情况。最早是由Papageorgiou等应用于人脸表示。<br> &nbsp; &nbsp; Haar特征分为三类：边缘特征、线性特征、中心特征和对角线特征，组合成特征模板。特征模板内有白色和黑色两种矩形，并定义该模板的特征值为白色矩形像素和减去黑色矩形像素和。 &nbsp;<br> &nbsp; &nbsp; 例如：脸部的一些特征能由矩形特征简单的描述，如：眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。但矩形特征只对一些简单的图形结构，如边缘、线段较敏感，所以只能描述特定走向（水平、垂直、对角）的结构。</span> <p></p> <h1><a name="t9"></a><span style="font-size:18px">7. DPM特征（<span style="font-size:18px">可变部件模型</span>）</span></h1> <p><span style="font-size:18px">&nbsp; &nbsp;&nbsp;DPM(Deformable Part Model)：可变部件模型<br> &nbsp; &nbsp; DPM是一个非常成功的目标检测算法，连续获得VOC（Visual Object Class）07,08,09年的检测冠军。目前已成为众多分类器、分割、人体姿态和行为分类的重要部分。2010年Pedro Felzenszwalb被VOC授予"终身成就奖"。DPM可以看做是HOG（Histogrrams of Oriented Gradients）的扩展，大体思路与HOG一致。先计算梯度方向直方图，然后用SVM（Surpport Vector Machine ）训练得到物体的梯度模型（Model）。有了这样的模板就可以直接用来分类了，简单理解就是模型和目标匹配。DPM只是在模型上做了很多改进工作。<br> </span></p> <h1><a name="t10"></a><span style="font-size:18px">8. 计算机视觉基本任务</span></h1> <p></p> <p><span style="font-size:18px">&nbsp; &nbsp; 计算机视觉的三个基本任务：</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp;1）对象检测(object detection)</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp;2）对象跟踪(object tracking)</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp;3）对象分割(object segmentation)</span></p> <h2><a name="t11"></a><span style="font-size:18px">8.1 对象检测</span></h2> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp;对象检测的目标：检测并定位图像或视频中的各类对象。对象类别：如人脸、行人、小汽车等。</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp;算法主要有：Haar-like、HOG、LBP、DPM</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp;HOG： 不能检测人的各种变化（人的关节会动）。</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp;DPM：需要离线训练且训练样本成本高。在实际使用时，不能处理大的变化。</span></p> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp;Video可比静态图像提供额外的信息：optical flow和motion constraints，这些信息可以辅助对象检测。运动特征计算量大。</span></p> <h2><a name="t12"></a><span style="font-size:18px">8.2 对象检测的非监督学习</span></h2> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp;对于图像或视频，收集完整的训练数据成本很高。所以基本一个基本模型，进行在线学习，从而获得分类的经验。</span></p> <p></p> <h2><a name="t13"></a><span style="font-size:18px">8.3 跟踪单个对象</span></h2> <span style="font-size:18px">&nbsp; &nbsp; &nbsp;1）Mean-shift&nbsp;</span> <p></p> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;所有相关的方法其计算量很大</span></p> <h2><a name="t14"></a><span style="font-size:18px">8.4 跟踪多个对象&nbsp;</span></h2> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp; 1）Markov-Chain Monte-Carlo Data Association (MCMCDA)</span></p> <h2><a name="t15"></a><span style="font-size:18px">8.5 人体分割(Human Segmentation)</span></h2> <p><span style="font-size:18px">&nbsp; &nbsp; &nbsp; 把人从背景中扣出来。 &nbsp;</span></p> ]]></content>
      
      
      
        <tags>
            
            <tag> CV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow</title>
      <link href="/2023/05/01/TensorFlow/"/>
      <url>/2023/05/01/TensorFlow/</url>
      
        <content type="html"><![CDATA[<hr> <h1><a name="t1"></a><a id="_41"></a>一.白话<a href="https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;神经网络\&quot;}&quot;}" data-tit="神经网络" data-pretit="神经网络">神经网络</a></h1> <p>第一部分将简单讲解"莫烦大神"网易云课程对神经网络的介绍，讲得清晰透彻，推荐大家阅读；第二部分将讲述我的理解。开始吧！让我们一起进入神经网络和TensorFlow的世界。</p> <p><img src="https://img-blog.csdnimg.cn/20191127195143597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p><strong>首先，什么是神经网络（Neural Networks）？</strong><br> 计算机神经网络是一种模仿生物神经网络或动物神经中枢，特别是大脑的结构和功能，它是一种数学模型或计算机模型。神经网络由大量的神经元连接并进行计算，大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应的过程。</p> <p>现代神经网络是一种基于传统统计学建模的工具，常用来对输入和输出间复杂的关系进行建模，或探索数据间的模式，神经网络是一种运算模型，有大量的节点或神经元及其联系构成。和人类的神经元一样，它们负责传递信息和加工信息，神经元也能被训练或强化，形成固定的神经形态，对特殊的信息有更强烈的反应。</p> <p><img src="https://img-blog.csdnimg.cn/20191127195334141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p><strong>神经网络是如何工作的呢？</strong><br> 如上图所示，不管这是一只跳跃飞奔的猫，或是一只静静思考的猫，你都知道它是一只猫，因为你的大脑已经被告知过圆眼睛、毛茸茸、尖耳朵的就是猫，你通过成熟的视觉神经系统判断它是猫。计算机也是一样，通过不断的训练，告诉哪些是猫、哪些是狗、哪些是猪，它们会通过数学模型来概括这些学习的判断，最终以数学的形式（0或1）来分类。目前，谷歌、百度图片搜索都能清晰识别事物，这些都归功于计算机神经系统的飞速发展。</p> <p>神经网络系统由多层神经层构成，为了区分不同的神经层，我们分为：</p> <ul><li>输入层：直接接收信息的神经层，比如接收一张猫的图片</li><li>输出层：信息在神经元中传递中转和分析权衡，形成输出结果，通过该层输出的结果可以看出计算机对事物的认知</li><li>隐藏层：在输入和输出层之间的众多神经元连接组成的各个层面，可以有多层，负责对传入信息的加工处理，经过多层加工才能衍生出对认知的理解</li></ul> <p><img src="https://img-blog.csdnimg.cn/20191127195813911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p><strong>神经网络举例说明</strong><br> 如下图所示，通常来说，计算机处理的东西和人类有所不同，无论是声音、图片还是文字，它们都只能以数字0或1出现在计算机神经网络里。神经网络看到的图片其实都是一堆数字，对数字的加工处理最终生成另一堆数字，并且具有一定认知上的意义，通过一点点的处理能够得知计算机到底判断这张图片是猫还是狗。</p> <p><img src="https://img-blog.csdnimg.cn/20191127200408932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p><strong>计算机是怎么训练的呢？</strong><br> 首先，需要很多的数据，比如需要计算机判断是猫还是狗，就需要准备上千万张有标记的图片，然后再进行上千万次的训练。计算机通过训练或强化学习判断猫，将获取的特征转换为数学的形式。</p> <p><img src="https://img-blog.csdnimg.cn/20191127200811475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p>我们需要做的就是只给计算机看图片，然后让它给我们一个不成熟也不准确的答案，有可能100次答案中有10%是正确的。如果给计算机看图片是一张飞奔的猫（如下图），但计算机可能识别成一条狗，尽管它识别错误，但这个错误对计算机是非常有价值的，可以用这次错误的经验作为一名好老师，不断学习经验。</p> <p><img src="https://img-blog.csdnimg.cn/20191127202223199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p><strong>那么计算机是如何学习经验的呢？</strong><br> 它是通过对比预测答案和真实答案的差别，然后把这种差别再反向传递回去，修改神经元的权重，让每个神经元向正确的方向改动一点点，这样到下次识别时，通过所有改进的神经网络，计算机识别的正确率会有所提高。最终每一次的一点点，累加上千万次的训练，就会朝正确的方向上迈出一大步。</p> <p><img src="https://img-blog.csdnimg.cn/20191127202401840.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p>最后到验收结果的时候，给计算机再次显示猫的图片时，它就能正确预测这是一只猫。</p> <p><img src="https://img-blog.csdnimg.cn/20191127202635872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p><strong>激励函数是什么东东？</strong><br> 接着再进一步看看神经网络是怎么训练的。原来在计算机里每一个神经元都有属于它的激励函数（Active Function），我们可以利用这些激励函数给计算机一个刺激行为。当我们第一次给计算机看一只飞奔的猫时，神经网络中只有部分神经元被激活或激励，被激活传递下去的信息是计算机最为重视的信息，也是对输出结果最有价值的信息。</p> <p><img src="https://img-blog.csdnimg.cn/20191127203147500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p>如果预测的结果是一只狗，所有神经元的参数就会被调整，这时有一些容易被激活的神经元就会变得迟钝，而另一些会变得敏感起来，这就说明了所有神经元参数正在被修改，变得对图片真正重要的信息敏感，从而被改动的参数就能渐渐预测出正确的答案，它就是一只猫。这就是神经网络的加工过程。</p> <p><img src="https://img-blog.csdnimg.cn/20191127203522349.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <hr> <h1><a name="t2"></a><a id="_98"></a>二.神经网络概念梳理</h1> <p>前面通过白话文讲述了神经网络之后，接下来我们对神经网络的概念从头再梳理一遍，这也是为后续深入学习奠定基础。</p> <p>神经网络(也称人工神经网络，ANN)算法是80年代机器学习界非常流行的算法，不过在90年代中途衰落。现在，携着“深度学习”之势，神经网络重装归来，重新成为最强大的机器学习算法之一。</p> <p><img src="https://img-blog.csdn.net/20151103023058400#pic_center" alt="在这里插入图片描述"></p> <p>人工神经网络（Artificial Neural Network，缩写ANN），是一种模仿生物神经网络的结构和功能的数学模型或计算模型。神经网络由大量的人工神经元联结进行计算。其来源于生物，故吴老先先讲述了生物神经网络的基础知识，从而进行引入。</p> <p><img src="https://img-blog.csdn.net/20151103023724578#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p><strong>神经细胞通过轴突将信号传递给其他的神经细胞，通过树突向各个方向接受信号。</strong><br> 神经细胞利用电-化学过程交换信号。输入信号来自另一些神经细胞。这些神经细胞的轴突末梢（也就是终端）和本神经细胞的树突相遇形成突触（synapse），信号就从树突上的突触进入本细胞。</p> <p>信号在大脑中实际怎样传输是一个相当复杂的过程，但就我们而言，重要的是把它看成和现代的计算机一样，利用一系列的0和1来进行操作。就是说，大脑的神经细胞也只有两种状态：兴奋（fire）和不兴奋（即抑制）。</p> <p><img src="https://img-blog.csdn.net/20151103024805255#pic_center" alt="在这里插入图片描述" width="400" height="250"></p> <p>神经细胞利用一种我们还不知道的方法，把所有从树突突触上进来的信号进行相加，如果全部信号的总和超过某个阈值，就会激发神经细胞进入兴奋（fire）状态，这时就会有一个电信号通过轴突发送出去给其他神经细胞。如果信号总和没有达到阈值，神经细胞就不会兴奋起来。这样的解释有点过分简单化，但已能满足我们的目的。</p> <p><img src="https://img-blog.csdn.net/20151103025739605#pic_center" alt="在这里插入图片描述" width="500" height="380"></p> <p>由于人脑具有一下几个特点：</p> <ul><li><strong>能实现无监督的学习</strong><br> 大脑能够自己进行学习，而不需要导师的监督教导。如果一个神经细胞在一段时间内受到高频率的刺激，则它和输入信号的神经细胞之间的连接强度就会按某种过程改变，使得该神经细胞下一次受到激励时更容易兴奋。</li><li><strong>对损伤有冗余性(tolerance)</strong><br> 大脑即使有很大一部分受到了损伤, 它仍然能够执行复杂的工作。</li><li><strong>处理信息的效率极高</strong><br> 神经细胞之间电-化学信号的传递，与一台数字计算机中CPU的数据传输相比，速度是非常慢的，但因神经细胞采用了并行的工作方式，使得大脑能够同时处理大量的数据。例如，大脑视觉皮层在处理通过我们的视网膜输入的一幅图象信号时，大约只要100ms的时间就能完成，眼睛并发执行。</li><li><strong>善于归纳推广</strong><br> 大脑和数字计算机不同，它极擅长的事情之一就是模式识别，并能根据已熟悉信息进行归纳推广(generlize)。例如，我们能够阅读他人所写的手稿上的文字，即使我们以前从来没见过他所写的东西。</li><li><strong>它是有意识的</strong></li></ul> <p><img src="https://img-blog.csdn.net/20151103032002251#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> <p>如下图所示，它表示的是一个人工神经细胞。其中：</p> <ul><li>输入(Input)</li><li>权重(Weight)：左边五个灰色圆底字母w代表浮点数</li><li>激励函数(Activation Function)：大圆，所有经过权重调整后的输入加起来，形成单个的激励值</li><li>输出(Output)：神经细胞的输出</li></ul> <p><img src="https://img-blog.csdnimg.cn/20191128153527248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="400" height="250"></p> <p>进入人工神经细胞的每一个input(输入)都与一个权重w相联系，正是这些权重将决定神经网络的整体活跃性。假设权重为-1和1之间的一个随机数，权重可正可负（激发和抑制作用）。当输入信号进入神经细胞时，它们的值将与它们对应的权重相乘，作为图中大圆的输入。如果激励值超过某个阀值（假设阀值为1.0），就会产生一个值为1的信号输出；如果激励值小于阀值1.0，则输出一个0。这是人工神经细胞激励函数的一种最简单的类型。涉及的数学知识如下图所示：</p> <p><img src="https://img-blog.csdn.net/20151103033932054#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>如果最后计算的结果激励值大于阈值1.0，则神经细胞就输出1；如果激励值小于阈值则输出0。这和一个生物神经细胞的兴奋状态或抑制状态是等价的。下面图是通过神经网络实现逻辑表达式与运算：（参考NG斯坦福机器学习讲义）</p> <p><img src="https://img-blog.csdn.net/20151103034617548#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>可以看到x1和x2变量作为神经网络的输入，当它们取不同的0或1值时，其结果通过sigmod函数计算的值是不同的。它模拟了整个AND运算。</p> <p><img src="https://img-blog.csdn.net/20151103035354873#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>该图中神经网络共有三层 ( 注输入层不是神经细胞，神经细胞只有两层 )：<br> <strong>输入层中的每个输入都馈送到了隐藏层，作为该层每一个神经细胞的输入；然后，从隐藏层的每个神经细胞的输出都连到了它下一层（即输出层）的每一个神经细胞。</strong></p> <p>注意：<br> 1.图中仅仅画了一个隐藏层，作为前馈网络，一般地可以有任意多个隐藏层。但在对付你将处理的大多数问题时一层通常是足够的。<br> 2.事实上，有一些问题甚至根本不需要任何隐藏单元，你只要把那些输入直接连结到输出神经细胞就行了。<br> 3.每一层实际都可以有任何数目的神经细胞，这完全取决于要解决的问题的复杂性。但神经细胞数目愈多，网络的工作速度也就愈低，网络的规模总是要求保持尽可能的小。</p> <p><img src="https://img-blog.csdn.net/20151103040150028#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>神经网络体系创建成功后，它必须接受训练来认出数字4，方法：<br> 1.先把神经网络的所有权重初始化为任意值；<br> 2.再给他一系列输入代表面板不同配置的输入，对每种输入配置，检查它的输出是什么，并调整相应权重；<br> 3.如果我们送给网络的输入模式不是4，则我们知道网络应该输出一个0。因此每个非4字符时，网络权重应进行调整，使得它的输出趋向于0；当代表4的模式输送给网络时，则应把权重调整到使其输出趋向于1；<br> 4.我们可以进一步识别0到9的所有数字或字母，其本质是手写识别的工作原理。<br> 5.最后，网络不单能认识已经训练的笔迹，还显示了它有显著的归纳和推广能力。</p> <p>正是这种归纳推广能力，使得神经网络已经成为能够用于无数应用的一种无价的工具，从人脸识别、医学诊断，直到跑马赛的预测，另外还有电脑游戏中的bot（作为游戏角色的机器人）的导航，或者硬件的robot（真正的机器人）的导航。</p> <p><img src="https://img-blog.csdn.net/20151103041044137#pic_center" alt="在这里插入图片描述" width="550" height="300"><br> 上图会演示神经网络在图像识别领域的一个著名应用，这个程序叫做LeNet，是一个基于多个隐层构建的神经网络。通过LeNet可以识别多种手写数字，并且达到很高的识别精度与拥有较好的鲁棒性。LeNet的发明人是机器学习的大牛Yann LeCun（目前google）。</p> <p>右下方的方形中显示的是输入计算机的图像，方形上方的红色字样“answer”后面显示的是计算机的输出。左边的三条竖直的图像列显示的是神经网络中三个隐藏层的输出，可以看出，随着层次的不断深入，越深的层次处理的细节越低，例如层3基本处理的都已经是线的细节了。</p> <p>这种类型的训练称作有监督的学习（supervised learnig），用来训练的数据称为训练集（training set）。调整权重可以采用许多不同的方法。对本类问题最常用的方法就是反向传播（backpropagation，简称backprop或BP）方法，即BP神经网络。</p> <p>你自己可以去学习另外的一种训练方式，即根本不需要任何导师来监督的训练，或称无监督学习（unsupervised learnig）。下图是神经网络的简单回顾与总结：</p> <p><img src="https://img-blog.csdn.net/20151103042300580#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>最后给大家看一个利用神经网络对图片进行分类的例子：过程就不详细论述了，图片很清晰，对人、汽车、摩托车、卡车进行图片识别，而具体的隐藏层函数需要大家去深入研究，我自己研究得也很浅显，抱歉~</p> <p><img src="https://img-blog.csdn.net/20151103042724702#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <hr> <h1><a name="t3"></a><a id="TensorFlow_194"></a>三.TensorFlow</h1> <h2><a name="t4"></a><a id="1TensorFlow_196"></a>1.TensorFlow简介</h2> <p>TensorFlow™是一个基于数据流编程（dataflow programming）的符号数学系统，被广泛应用于各类机器学习（machine learning）算法的编程实现，其前身是谷歌的神经网络算法库DistBelief 。Tensorflow拥有多层级结构，可部署于各类服务器、PC终端和网页并支持GPU和TPU高性能数值计算，被广泛应用于谷歌内部的产品开发和各领域的科学研究 。</p> <p>TensorFlow由谷歌人工智能团队谷歌大脑（Google Brain）开发和维护，拥有包括TensorFlow Hub、TensorFlow Lite、TensorFlow Research Cloud在内的多个项目以及各类应用程序接口（Application Programming Interface, API）。</p> <p>TensorFlow官网：<a href="https://tensorflow.google.cn/">https://tensorflow.google.cn/</a></p> <p><img src="https://img-blog.csdnimg.cn/20191128160138638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> <p>TensorFlow 是一个端到端开源机器学习平台。它拥有一个包含各种工具、库和社区资源的全面灵活生态系统，可以让研究人员推动机器学习领域的先进技术的发展，并让开发者轻松地构建和部署由机器学习提供支持的应用。总之，如果有TensorFlow，我们就可以很自如地玩转神经网络。</p> <p><img src="https://img-blog.csdnimg.cn/20191128160239614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> <p><img src="https://img-blog.csdnimg.cn/20191128160247489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> <hr> <h2><a name="t5"></a><a id="2_214"></a>2.安装过程</h2> <p>TensorFlow即可以支持CPU，也可以支持CPU+GPU。前者的环境需求简单，后者需要额外的支持。TensorFlow的安装方式很多，包括：</p> <ul><li>pip 安装</li><li>virtualenv安装</li><li>docker安装</li><li>从安装源安装</li></ul> <p>本文将使用pip安装，pip在每个系统的安装方式包括：</p> <ul><li>Linux \ MacOS \ Windows</li><li>CPU版 \ GPU版（GPU版本比CPU版本快很多倍）</li><li>测试版</li><li>更新TensorFlow</li></ul> <p>TensorFlow支持Windows用户，由于我的计算机是Windows操作系统，这里使用该方法进行安装，这里安装的环境为：<strong>Windows10+CPU+TensorFlow2.0+Anaconda+Python3.6</strong></p> <br> <p><strong>第一步：官网下载Anaconda并安装</strong></p> <p><img src="https://img-blog.csdnimg.cn/20191128161531571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="300"></p> <p><strong>第二步：安装Anaconda之后，打开“Anaconda Prompt”命令行，检查Anaconda是否安装成功及环境</strong></p> <pre data-index="0" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token comment">//检查Anaconda是否成功安装</span>conda <span class="token operator">--</span>version<span class="token comment">//检测目前安装了哪些环境</span>conda info <span class="token operator">--</span>envs<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128161709258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> <p><strong>第三步：检查当前环境可以安装哪些版本的Python，作者选择Python3.6版本</strong></p> <pre data-index="1" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">conda search <span class="token operator">--</span>full<span class="token operator">-</span>name python<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128162414841.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> <p>由于作者电脑不支持GPU，所以这里只安装CPU版本，GPU安装推荐下面文章。<br> <a href="https://blog.csdn.net/wangbowj123/article/details/89381562">tensorflow2.0GPU版本的环境配置与安装教程 normalization</a><br> <a href="https://blog.csdn.net/u011119817/article/details/88309256">[Tensorflow2.0] Tensorflow2.0的安装教程 - 牛andmore牛</a></p> <p><img src="https://img-blog.csdnimg.cn/20191128162420952.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p><strong>第四步：创建环境，用来安装tensorflow2.0以及相关的python packages</strong></p> <pre data-index="2" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">conda create <span class="token operator">-</span>n tf2 python<span class="token operator">=</span><span class="token number">3.6</span><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128164102712.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p><img src="https://img-blog.csdnimg.cn/20191128164331680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p><strong>第五步：激活TensorFlow</strong></p> <pre data-index="3" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">activate tf2<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128164559459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p><strong>第六步：安装cpu版本TensorFlow</strong></p> <pre data-index="4" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">pip install tensorflow<span class="token operator">==</span><span class="token number">2.0</span><span class="token number">.0</span><span class="token operator">-</span>alpha0<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> <ul><li>conda search tensorflow #搜CPU版</li><li>conda search tensorflow-gpu #搜GPU版</li><li>conda install tensorflow=2.0.0 #安装CPU版</li><li>conda install tensorflow-gpu=2.0.0 #安装GPU版</li></ul> <p><img src="https://img-blog.csdnimg.cn/20191128164710277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p><img src="https://img-blog.csdnimg.cn/20191128164720358.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p>此时，表示安装结束，接下来开始确认我们是否安装成功。</p> <p><strong>第七：打开Anaconda Navigator，选择环境“tf2”，点击spyder下面的“install”。</strong></p> <p><img src="https://img-blog.csdnimg.cn/20191128165058698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p>安装好就变成“Launch”了，点击就可以进去了。</p> <p><img src="https://img-blog.csdnimg.cn/20191128165155272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="300" height="300"></p> <p><strong>第八步：输入代码验证是否安装成功。</strong></p> <pre data-index="5" class="prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf <span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128165238554.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p>如果需要退出环境，可以输入下面命令。</p> <p><img src="https://img-blog.csdnimg.cn/2019112816535080.png#pic_center" alt="在这里插入图片描述"></p> <hr> <h2><a name="t6"></a><a id="3_321"></a>3.基础入门</h2> <p>最后给出一个简单的实例代码：</p> <pre data-index="6" class="set-code-hide prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token comment"># -*- coding: utf-8 -*-</span><span class="token triple-quoted-string string">"""Spyder Editor<p>This is a temporary script file.</p><p>By：Eastmount CSDN YXZ 2019-11-28<br>“””</p><p><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf </p><p><span class="token comment">#查询TensorFlow版本</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span><strong>version</strong><span class="token punctuation">)</span></p><p><span class="token comment">#定义a和b为两个常量</span><br>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">“a”</span><span class="token punctuation">)</span><br>b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">“b”</span><span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span></p><p><span class="token comment">#随机生成一个正态分布</span><br>output <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></p><p><span class="token comment">#创建2个矩阵并进行相乘</span><br>matrix1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br>matrix2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br>product <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>matrix1<span class="token punctuation">,</span>matrix2<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>matrix1<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>matrix2<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>product<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>product<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></p><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></span></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li></ul></pre> <p>输出结果如下所示：</p> <pre data-index="7" class="set-code-hide prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token number">2.0</span><span class="token number">.0</span><span class="token operator">-</span>alpha0<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span></p><p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.1826832</span>  <span class="token operator">-</span><span class="token number">0.32986134</span> <span class="token operator">-</span><span class="token number">1.6238695</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.18214056</span>  <span class="token number">0.25923613</span> <span class="token operator">-</span><span class="token number">0.12570491</span><span class="token punctuation">]</span><br> <span class="token punctuation">[</span> <span class="token number">1.0550841</span>  <span class="token operator">-</span><span class="token number">0.6655764</span>  <span class="token operator">-</span><span class="token number">1.5837296</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.10004017</span>  <span class="token number">0.0162886</span>   <span class="token number">0.9483853</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span> <span class="token number">0.4709251</span>  <span class="token operator">-</span><span class="token number">0.18713968</span>  <span class="token number">0.8347026</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span></p><p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span></p><p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">12</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">12</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span></p><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li></ul></pre> <hr> <h1><a name="t7"></a><a id="_388"></a>四.总结</h1> <p>最后希望基础性文章对您有所帮助，作者也是这个领域的菜鸟一枚，希望与您共同进步，后续会继续深入分享Python人工智能系列，如果喜欢点个赞评论，共勉~</p> <p><img src="https://img-blog.csdnimg.cn/20191128170443362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="300" height="400"></p> <p>中午惊喜收到女神的小蛋糕，下午期末考试，一直忙到凌晨2点，静寂中又涨了一岁。花开蝴蝶自然来，希望自己一直善良下去，品尝到更多幸福的味道。感谢这些年所有帮助和祝福我的人，无以回报，只能去帮助更多的人，分享更好的博客，备好每一次讲台前的课程。忙中带乐，晚安娜，明天接着奋斗~</p> <p>(By:Eastmount 2019-11-28 下午4点 <a href="http://blog.csdn.net/eastmount/">http://blog.csdn.net/eastmount/</a> )</p>                <div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/Eastmount/article/details/103282042&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-98b95bb57c.css" rel="stylesheet">                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-c216769e99.css" rel="stylesheet">        ](<div id="article_content" class="article_content clearfix">        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-25cebea3f9.css">                <div id="content_views" class="markdown_views prism-atom-one-dark">                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>                    </svg>                    <p>从本篇文章开始，作者正式开始研究Python<a href="https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;深度学习\&quot;}&quot;}" data-tit="深度学习" data-pretit="深度学习">深度学习</a>、神经网络及人工智能相关知识。第一篇文章主要讲解神经网络基础概念，同时讲解TensorFlow2.0的安装过程及基础用法，主要结合作者之前的博客和"莫烦大神"的视频介绍，后面随着深入会讲解具体的项目及应用。基础性文章，希望对您有所帮助，如果文章中存在错误或不足之处，还请海涵~同时自己也是人工智能的菜鸟，希望大家能与我在这一笔一划的博客中成长起来。</p> <p></p> <div class="toc">  <h3><a name="t0"></a>文章目录</h3>  <ul><li><a href="#_41" target="_self">一.白话神经网络</a></li><li><a href="#_98" target="_self">二.神经网络概念梳理</a></li><li><a href="#TensorFlow_194" target="_self">三.TensorFlow</a></li><li><ul><li><a href="#1TensorFlow_196" target="_self">1.TensorFlow简介</a></li><li><a href="#2_214" target="_self">2.安装过程</a></li><li><a href="#3_321" target="_self">3.基础入门</a></li></ul>   </li><li><a href="#_388" target="_self">四.总结</a></li></ul> </div> <br> 同时推荐前面作者另外三个Python系列文章。从2014年开始，作者主要写了三个Python系列文章，分别是基础知识、网络爬虫和数据分析。2018年陆续增加了Python图像识别和Python人工智能专栏。 <p></p> <ul><li>Python基础知识系列：<a href="https://blog.csdn.net/eastmount/category_2547623.html">Pythonj基础知识学习与提升</a></li><li>Python网络爬虫系列：<a href="https://blog.csdn.net/eastmount/category_9264385.html">Python爬虫之Selenium+Phantomjs+CasperJS</a></li><li>Python数据分析系列：<a href="https://blog.csdn.net/eastmount/category_9265165.html">知识图谱、web数据挖掘及NLP</a></li><li>Python图像识别系列：<a href="https://blog.csdn.net/eastmount/category_9278090.html">Python图像处理及图像识别</a></li></ul> <p><img src="https://img-blog.csdnimg.cn/2019112810131675.png#pic_center" alt="在这里插入图片描述"></p> <p>代码下载地址（欢迎大家关注点赞）：</p> <ul><li><a href="https://github.com/eastmountyxz/AI-for-TensorFlow">https://github.com/eastmountyxz/AI-for-TensorFlow</a></li><li><a href="https://github.com/eastmountyxz/AI-for-Keras">https://github.com/eastmountyxz/AI-for-Keras</a></li></ul> <p><strong>作者theano人工智能系列：</strong><br> <a href="https://blog.csdn.net/Eastmount/article/details/80363106">[Python人工智能] 一.神经网络入门及theano基础代码讲解</a><br> <a href="https://blog.csdn.net/Eastmount/article/details/80390462">[Python人工智能] 二.theano实现回归神经网络分析</a><br> <a href="https://blog.csdn.net/Eastmount/article/details/80432844">[Python人工智能] 三.theano实现分类神经网络及机器学习基础</a><br> <a href="https://blog.csdn.net/Eastmount/article/details/80499259">[Python人工智能] 四.神经网络和深度学习入门知识</a><br> <a href="https://blog.csdn.net/Eastmount/article/details/80536725">[Python人工智能] 五.theano实现神经网络正规化Regularization处理</a><br> <a href="https://blog.csdn.net/Eastmount/article/details/80650980">[Python人工智能] 六.神经网络的评价指标、特征标准化和特征选择</a><br> <a href="https://blog.csdn.net/Eastmount/article/details/80757556">[Python人工智能] 七.加速神经网络、激励函数和过拟合</a></p> <p>参考文献：<br> <a href="https://blog.csdn.net/eastmount/article/details/49591349">神经网络和机器学习基础入门分享 - 作者的文章</a><br> <a href="https://blog.csdn.net/abcjennifer/article/details/7758797">Stanford机器学习—第五讲. 神经网络的学习 Neural Networks learning</a><br> <a href="https://blog.csdn.net/zzwu/article/details/574931">吴祖增前辈：神经网络入门(连载之一)</a><br> <a href="https://blog.csdn.net/zzwu/article/details/575050">吴祖增前辈：神经网络入门(连载之二)</a><br> 斯坦福机器学习视频NG教授： <a href="https://class.coursera.org/ml/class/index">https://class.coursera.org/ml/class/index</a><br> 书籍《游戏开发中的人工智能》、《游戏编程中的人工智能技术》<br> 网易云莫烦老师视频（强推）：<a href="https://study.163.com/course/courseLearn.htm?courseId=1003209007">https://study.163.com/course/courseLearn.htm?courseId=1003209007</a><br> <a href="https://blog.csdn.net/Eppley/article/details/79297503">TensorFlow在Win10上的安装教程和简单示例 - Suffering</a><br> <a href="https://blog.csdn.net/u011119817/article/details/88309256">[Tensorflow2.0] Tensorflow2.0的安装教程 - 牛andmore牛</a></p> <hr> <h1><a name="t1"></a><a id="_41"></a>一.白话<a href="https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;神经网络\&quot;}&quot;}" data-tit="神经网络" data-pretit="神经网络">神经网络</a></h1> <p>第一部分将简单讲解"莫烦大神"网易云课程对神经网络的介绍，讲得清晰透彻，推荐大家阅读；第二部分将讲述我的理解。开始吧！让我们一起进入神经网络和TensorFlow的世界。</p> <p><img src="https://img-blog.csdnimg.cn/20191127195143597.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p><strong>首先，什么是神经网络（Neural Networks）？</strong><br> 计算机神经网络是一种模仿生物神经网络或动物神经中枢，特别是大脑的结构和功能，它是一种数学模型或计算机模型。神经网络由大量的神经元连接并进行计算，大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应的过程。</p> <p>现代神经网络是一种基于传统统计学建模的工具，常用来对输入和输出间复杂的关系进行建模，或探索数据间的模式，神经网络是一种运算模型，有大量的节点或神经元及其联系构成。和人类的神经元一样，它们负责传递信息和加工信息，神经元也能被训练或强化，形成固定的神经形态，对特殊的信息有更强烈的反应。</p> <p><img src="https://img-blog.csdnimg.cn/20191127195334141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p><strong>神经网络是如何工作的呢？</strong><br> 如上图所示，不管这是一只跳跃飞奔的猫，或是一只静静思考的猫，你都知道它是一只猫，因为你的大脑已经被告知过圆眼睛、毛茸茸、尖耳朵的就是猫，你通过成熟的视觉神经系统判断它是猫。计算机也是一样，通过不断的训练，告诉哪些是猫、哪些是狗、哪些是猪，它们会通过数学模型来概括这些学习的判断，最终以数学的形式（0或1）来分类。目前，谷歌、百度图片搜索都能清晰识别事物，这些都归功于计算机神经系统的飞速发展。</p> <p>神经网络系统由多层神经层构成，为了区分不同的神经层，我们分为：</p> <ul><li>输入层：直接接收信息的神经层，比如接收一张猫的图片</li><li>输出层：信息在神经元中传递中转和分析权衡，形成输出结果，通过该层输出的结果可以看出计算机对事物的认知</li><li>隐藏层：在输入和输出层之间的众多神经元连接组成的各个层面，可以有多层，负责对传入信息的加工处理，经过多层加工才能衍生出对认知的理解</li></ul> <p><img src="https://img-blog.csdnimg.cn/20191127195813911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p><strong>神经网络举例说明</strong><br> 如下图所示，通常来说，计算机处理的东西和人类有所不同，无论是声音、图片还是文字，它们都只能以数字0或1出现在计算机神经网络里。神经网络看到的图片其实都是一堆数字，对数字的加工处理最终生成另一堆数字，并且具有一定认知上的意义，通过一点点的处理能够得知计算机到底判断这张图片是猫还是狗。</p> <p><img src="https://img-blog.csdnimg.cn/20191127200408932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p><strong>计算机是怎么训练的呢？</strong><br> 首先，需要很多的数据，比如需要计算机判断是猫还是狗，就需要准备上千万张有标记的图片，然后再进行上千万次的训练。计算机通过训练或强化学习判断猫，将获取的特征转换为数学的形式。</p> <p><img src="https://img-blog.csdnimg.cn/20191127200811475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="450" height="300"></p> <p>我们需要做的就是只给计算机看图片，然后让它给我们一个不成熟也不准确的答案，有可能100次答案中有10%是正确的。如果给计算机看图片是一张飞奔的猫（如下图），但计算机可能识别成一条狗，尽管它识别错误，但这个错误对计算机是非常有价值的，可以用这次错误的经验作为一名好老师，不断学习经验。</p> <p><img src="https://img-blog.csdnimg.cn/20191127202223199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p><strong>那么计算机是如何学习经验的呢？</strong><br> 它是通过对比预测答案和真实答案的差别，然后把这种差别再反向传递回去，修改神经元的权重，让每个神经元向正确的方向改动一点点，这样到下次识别时，通过所有改进的神经网络，计算机识别的正确率会有所提高。最终每一次的一点点，累加上千万次的训练，就会朝正确的方向上迈出一大步。</p> <p><img src="https://img-blog.csdnimg.cn/20191127202401840.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p>最后到验收结果的时候，给计算机再次显示猫的图片时，它就能正确预测这是一只猫。</p> <p><img src="https://img-blog.csdnimg.cn/20191127202635872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p><strong>激励函数是什么东东？</strong><br> 接着再进一步看看神经网络是怎么训练的。原来在计算机里每一个神经元都有属于它的激励函数（Active Function），我们可以利用这些激励函数给计算机一个刺激行为。当我们第一次给计算机看一只飞奔的猫时，神经网络中只有部分神经元被激活或激励，被激活传递下去的信息是计算机最为重视的信息，也是对输出结果最有价值的信息。</p> <p><img src="https://img-blog.csdnimg.cn/20191127203147500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p>如果预测的结果是一只狗，所有神经元的参数就会被调整，这时有一些容易被激活的神经元就会变得迟钝，而另一些会变得敏感起来，这就说明了所有神经元参数正在被修改，变得对图片真正重要的信息敏感，从而被改动的参数就能渐渐预测出正确的答案，它就是一只猫。这就是神经网络的加工过程。</p> <p><img src="https://img-blog.csdnimg.cn/20191127203522349.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <hr> <h1><a name="t2"></a><a id="_98"></a>二.神经网络概念梳理</h1> <p>前面通过白话文讲述了神经网络之后，接下来我们对神经网络的概念从头再梳理一遍，这也是为后续深入学习奠定基础。</p> <p>神经网络(也称人工神经网络，ANN)算法是80年代机器学习界非常流行的算法，不过在90年代中途衰落。现在，携着“深度学习”之势，神经网络重装归来，重新成为最强大的机器学习算法之一。</p> <p><img src="https://img-blog.csdn.net/20151103023058400#pic_center" alt="在这里插入图片描述"></p> <p>人工神经网络（Artificial Neural Network，缩写ANN），是一种模仿生物神经网络的结构和功能的数学模型或计算模型。神经网络由大量的人工神经元联结进行计算。其来源于生物，故吴老先先讲述了生物神经网络的基础知识，从而进行引入。</p> <p><img src="https://img-blog.csdn.net/20151103023724578#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p><strong>神经细胞通过轴突将信号传递给其他的神经细胞，通过树突向各个方向接受信号。</strong><br> 神经细胞利用电-化学过程交换信号。输入信号来自另一些神经细胞。这些神经细胞的轴突末梢（也就是终端）和本神经细胞的树突相遇形成突触（synapse），信号就从树突上的突触进入本细胞。</p> <p>信号在大脑中实际怎样传输是一个相当复杂的过程，但就我们而言，重要的是把它看成和现代的计算机一样，利用一系列的0和1来进行操作。就是说，大脑的神经细胞也只有两种状态：兴奋（fire）和不兴奋（即抑制）。</p> <p><img src="https://img-blog.csdn.net/20151103024805255#pic_center" alt="在这里插入图片描述" width="400" height="250"></p> <p>神经细胞利用一种我们还不知道的方法，把所有从树突突触上进来的信号进行相加，如果全部信号的总和超过某个阈值，就会激发神经细胞进入兴奋（fire）状态，这时就会有一个电信号通过轴突发送出去给其他神经细胞。如果信号总和没有达到阈值，神经细胞就不会兴奋起来。这样的解释有点过分简单化，但已能满足我们的目的。</p> <p><img src="https://img-blog.csdn.net/20151103025739605#pic_center" alt="在这里插入图片描述" width="500" height="380"></p> <p>由于人脑具有一下几个特点：</p> <ul><li><strong>能实现无监督的学习</strong><br> 大脑能够自己进行学习，而不需要导师的监督教导。如果一个神经细胞在一段时间内受到高频率的刺激，则它和输入信号的神经细胞之间的连接强度就会按某种过程改变，使得该神经细胞下一次受到激励时更容易兴奋。</li><li><strong>对损伤有冗余性(tolerance)</strong><br> 大脑即使有很大一部分受到了损伤, 它仍然能够执行复杂的工作。</li><li><strong>处理信息的效率极高</strong><br> 神经细胞之间电-化学信号的传递，与一台数字计算机中CPU的数据传输相比，速度是非常慢的，但因神经细胞采用了并行的工作方式，使得大脑能够同时处理大量的数据。例如，大脑视觉皮层在处理通过我们的视网膜输入的一幅图象信号时，大约只要100ms的时间就能完成，眼睛并发执行。</li><li><strong>善于归纳推广</strong><br> 大脑和数字计算机不同，它极擅长的事情之一就是模式识别，并能根据已熟悉信息进行归纳推广(generlize)。例如，我们能够阅读他人所写的手稿上的文字，即使我们以前从来没见过他所写的东西。</li><li><strong>它是有意识的</strong></li></ul> <p><img src="https://img-blog.csdn.net/20151103032002251#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> <p>如下图所示，它表示的是一个人工神经细胞。其中：</p> <ul><li>输入(Input)</li><li>权重(Weight)：左边五个灰色圆底字母w代表浮点数</li><li>激励函数(Activation Function)：大圆，所有经过权重调整后的输入加起来，形成单个的激励值</li><li>输出(Output)：神经细胞的输出</li></ul> <p><img src="https://img-blog.csdnimg.cn/20191128153527248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="400" height="250"></p> <p>进入人工神经细胞的每一个input(输入)都与一个权重w相联系，正是这些权重将决定神经网络的整体活跃性。假设权重为-1和1之间的一个随机数，权重可正可负（激发和抑制作用）。当输入信号进入神经细胞时，它们的值将与它们对应的权重相乘，作为图中大圆的输入。如果激励值超过某个阀值（假设阀值为1.0），就会产生一个值为1的信号输出；如果激励值小于阀值1.0，则输出一个0。这是人工神经细胞激励函数的一种最简单的类型。涉及的数学知识如下图所示：</p> <p><img src="https://img-blog.csdn.net/20151103033932054#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>如果最后计算的结果激励值大于阈值1.0，则神经细胞就输出1；如果激励值小于阈值则输出0。这和一个生物神经细胞的兴奋状态或抑制状态是等价的。下面图是通过神经网络实现逻辑表达式与运算：（参考NG斯坦福机器学习讲义）</p> <p><img src="https://img-blog.csdn.net/20151103034617548#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>可以看到x1和x2变量作为神经网络的输入，当它们取不同的0或1值时，其结果通过sigmod函数计算的值是不同的。它模拟了整个AND运算。</p> <p><img src="https://img-blog.csdn.net/20151103035354873#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>该图中神经网络共有三层 ( 注输入层不是神经细胞，神经细胞只有两层 )：<br> <strong>输入层中的每个输入都馈送到了隐藏层，作为该层每一个神经细胞的输入；然后，从隐藏层的每个神经细胞的输出都连到了它下一层（即输出层）的每一个神经细胞。</strong></p> <p>注意：<br> 1.图中仅仅画了一个隐藏层，作为前馈网络，一般地可以有任意多个隐藏层。但在对付你将处理的大多数问题时一层通常是足够的。<br> 2.事实上，有一些问题甚至根本不需要任何隐藏单元，你只要把那些输入直接连结到输出神经细胞就行了。<br> 3.每一层实际都可以有任何数目的神经细胞，这完全取决于要解决的问题的复杂性。但神经细胞数目愈多，网络的工作速度也就愈低，网络的规模总是要求保持尽可能的小。</p> <p><img src="https://img-blog.csdn.net/20151103040150028#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>神经网络体系创建成功后，它必须接受训练来认出数字4，方法：<br> 1.先把神经网络的所有权重初始化为任意值；<br> 2.再给他一系列输入代表面板不同配置的输入，对每种输入配置，检查它的输出是什么，并调整相应权重；<br> 3.如果我们送给网络的输入模式不是4，则我们知道网络应该输出一个0。因此每个非4字符时，网络权重应进行调整，使得它的输出趋向于0；当代表4的模式输送给网络时，则应把权重调整到使其输出趋向于1；<br> 4.我们可以进一步识别0到9的所有数字或字母，其本质是手写识别的工作原理。<br> 5.最后，网络不单能认识已经训练的笔迹，还显示了它有显著的归纳和推广能力。</p> <p>正是这种归纳推广能力，使得神经网络已经成为能够用于无数应用的一种无价的工具，从人脸识别、医学诊断，直到跑马赛的预测，另外还有电脑游戏中的bot（作为游戏角色的机器人）的导航，或者硬件的robot（真正的机器人）的导航。</p> <p><img src="https://img-blog.csdn.net/20151103041044137#pic_center" alt="在这里插入图片描述" width="550" height="300"><br> 上图会演示神经网络在图像识别领域的一个著名应用，这个程序叫做LeNet，是一个基于多个隐层构建的神经网络。通过LeNet可以识别多种手写数字，并且达到很高的识别精度与拥有较好的鲁棒性。LeNet的发明人是机器学习的大牛Yann LeCun（目前google）。</p> <p>右下方的方形中显示的是输入计算机的图像，方形上方的红色字样“answer”后面显示的是计算机的输出。左边的三条竖直的图像列显示的是神经网络中三个隐藏层的输出，可以看出，随着层次的不断深入，越深的层次处理的细节越低，例如层3基本处理的都已经是线的细节了。</p> <p>这种类型的训练称作有监督的学习（supervised learnig），用来训练的数据称为训练集（training set）。调整权重可以采用许多不同的方法。对本类问题最常用的方法就是反向传播（backpropagation，简称backprop或BP）方法，即BP神经网络。</p> <p>你自己可以去学习另外的一种训练方式，即根本不需要任何导师来监督的训练，或称无监督学习（unsupervised learnig）。下图是神经网络的简单回顾与总结：</p> <p><img src="https://img-blog.csdn.net/20151103042300580#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p>最后给大家看一个利用神经网络对图片进行分类的例子：过程就不详细论述了，图片很清晰，对人、汽车、摩托车、卡车进行图片识别，而具体的隐藏层函数需要大家去深入研究，我自己研究得也很浅显，抱歉~</p> <p><img src="https://img-blog.csdn.net/20151103042724702#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <hr> <h1><a name="t3"></a><a id="TensorFlow_194"></a>三.TensorFlow</h1> <h2><a name="t4"></a><a id="1TensorFlow_196"></a>1.TensorFlow简介</h2> <p>TensorFlow™是一个基于数据流编程（dataflow programming）的符号数学系统，被广泛应用于各类机器学习（machine learning）算法的编程实现，其前身是谷歌的神经网络算法库DistBelief 。Tensorflow拥有多层级结构，可部署于各类服务器、PC终端和网页并支持GPU和TPU高性能数值计算，被广泛应用于谷歌内部的产品开发和各领域的科学研究 。</p> <p>TensorFlow由谷歌人工智能团队谷歌大脑（Google Brain）开发和维护，拥有包括TensorFlow Hub、TensorFlow Lite、TensorFlow Research Cloud在内的多个项目以及各类应用程序接口（Application Programming Interface, API）。</p> <p>TensorFlow官网：<a href="https://tensorflow.google.cn/">https://tensorflow.google.cn/</a></p> <p><img src="https://img-blog.csdnimg.cn/20191128160138638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> <p>TensorFlow 是一个端到端开源机器学习平台。它拥有一个包含各种工具、库和社区资源的全面灵活生态系统，可以让研究人员推动机器学习领域的先进技术的发展，并让开发者轻松地构建和部署由机器学习提供支持的应用。总之，如果有TensorFlow，我们就可以很自如地玩转神经网络。</p> <p><img src="https://img-blog.csdnimg.cn/20191128160239614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> <p><img src="https://img-blog.csdnimg.cn/20191128160247489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="350"></p> <hr> <h2><a name="t5"></a><a id="2_214"></a>2.安装过程</h2> <p>TensorFlow即可以支持CPU，也可以支持CPU+GPU。前者的环境需求简单，后者需要额外的支持。TensorFlow的安装方式很多，包括：</p> <ul><li>pip 安装</li><li>virtualenv安装</li><li>docker安装</li><li>从安装源安装</li></ul> <p>本文将使用pip安装，pip在每个系统的安装方式包括：</p> <ul><li>Linux \ MacOS \ Windows</li><li>CPU版 \ GPU版（GPU版本比CPU版本快很多倍）</li><li>测试版</li><li>更新TensorFlow</li></ul> <p>TensorFlow支持Windows用户，由于我的计算机是Windows操作系统，这里使用该方法进行安装，这里安装的环境为：<strong>Windows10+CPU+TensorFlow2.0+Anaconda+Python3.6</strong></p> <br> <p><strong>第一步：官网下载Anaconda并安装</strong></p> <p><img src="https://img-blog.csdnimg.cn/20191128161531571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="600" height="300"></p> <p><strong>第二步：安装Anaconda之后，打开“Anaconda Prompt”命令行，检查Anaconda是否安装成功及环境</strong></p> <pre data-index="0" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token comment">//检查Anaconda是否成功安装</span>conda <span class="token operator">--</span>version<span class="token comment">//检测目前安装了哪些环境</span>conda info <span class="token operator">--</span>envs<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128161709258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> <p><strong>第三步：检查当前环境可以安装哪些版本的Python，作者选择Python3.6版本</strong></p> <pre data-index="1" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">conda search <span class="token operator">--</span>full<span class="token operator">-</span>name python<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128162414841.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="250"></p> <p>由于作者电脑不支持GPU，所以这里只安装CPU版本，GPU安装推荐下面文章。<br> <a href="https://blog.csdn.net/wangbowj123/article/details/89381562">tensorflow2.0GPU版本的环境配置与安装教程 normalization</a><br> <a href="https://blog.csdn.net/u011119817/article/details/88309256">[Tensorflow2.0] Tensorflow2.0的安装教程 - 牛andmore牛</a></p> <p><img src="https://img-blog.csdnimg.cn/20191128162420952.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="350"></p> <p><strong>第四步：创建环境，用来安装tensorflow2.0以及相关的python packages</strong></p> <pre data-index="2" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">conda create <span class="token operator">-</span>n tf2 python<span class="token operator">=</span><span class="token number">3.6</span><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128164102712.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p><img src="https://img-blog.csdnimg.cn/20191128164331680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p><strong>第五步：激活TensorFlow</strong></p> <pre data-index="3" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">activate tf2<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128164559459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p><strong>第六步：安装cpu版本TensorFlow</strong></p> <pre data-index="4" class="prettyprint"><code class="prism language-c has-numbering" onclick="mdcp.signin(event)" style="position: unset;">pip install tensorflow<span class="token operator">==</span><span class="token number">2.0</span><span class="token number">.0</span><span class="token operator">-</span>alpha0<div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li></ul></pre> <ul><li>conda search tensorflow #搜CPU版</li><li>conda search tensorflow-gpu #搜GPU版</li><li>conda install tensorflow=2.0.0 #安装CPU版</li><li>conda install tensorflow-gpu=2.0.0 #安装GPU版</li></ul> <p><img src="https://img-blog.csdnimg.cn/20191128164710277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="200"></p> <p><img src="https://img-blog.csdnimg.cn/20191128164720358.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p>此时，表示安装结束，接下来开始确认我们是否安装成功。</p> <p><strong>第七：打开Anaconda Navigator，选择环境“tf2”，点击spyder下面的“install”。</strong></p> <p><img src="https://img-blog.csdnimg.cn/20191128165058698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p>安装好就变成“Launch”了，点击就可以进去了。</p> <p><img src="https://img-blog.csdnimg.cn/20191128165155272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="300" height="300"></p> <p><strong>第八步：输入代码验证是否安装成功。</strong></p> <pre data-index="5" class="prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf <span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/20191128165238554.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="500" height="300"></p> <p>如果需要退出环境，可以输入下面命令。</p> <p><img src="https://img-blog.csdnimg.cn/2019112816535080.png#pic_center" alt="在这里插入图片描述"></p> <hr> <h2><a name="t6"></a><a id="3_321"></a>3.基础入门</h2> <p>最后给出一个简单的实例代码：</p> <pre data-index="6" class="set-code-hide prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token comment"># -*- coding: utf-8 -*-</span><span class="token triple-quoted-string string">"""Spyder Editor<p>This is a temporary script file.</p><p>By：Eastmount CSDN YXZ 2019-11-28<br>“””</p><p><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf </p><p><span class="token comment">#查询TensorFlow版本</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span><strong>version</strong><span class="token punctuation">)</span></p><p><span class="token comment">#定义a和b为两个常量</span><br>a <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">“a”</span><span class="token punctuation">)</span><br>b <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">“b”</span><span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span></p><p><span class="token comment">#随机生成一个正态分布</span><br>output <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></p><p><span class="token comment">#创建2个矩阵并进行相乘</span><br>matrix1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br>matrix2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><br>product <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>matrix1<span class="token punctuation">,</span>matrix2<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>matrix1<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>matrix2<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>product<span class="token punctuation">)</span><br><span class="token keyword">print</span><span class="token punctuation">(</span>product<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></p><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></span></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li></ul></pre> <p>输出结果如下所示：</p> <pre data-index="7" class="set-code-hide prettyprint"><code class="prism language-python has-numbering" onclick="mdcp.signin(event)" style="position: unset;"><span class="token number">2.0</span><span class="token number">.0</span><span class="token operator">-</span>alpha0<p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span></p><p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.1826832</span>  <span class="token operator">-</span><span class="token number">0.32986134</span> <span class="token operator">-</span><span class="token number">1.6238695</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.18214056</span>  <span class="token number">0.25923613</span> <span class="token operator">-</span><span class="token number">0.12570491</span><span class="token punctuation">]</span><br> <span class="token punctuation">[</span> <span class="token number">1.0550841</span>  <span class="token operator">-</span><span class="token number">0.6655764</span>  <span class="token operator">-</span><span class="token number">1.5837296</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.10004017</span>  <span class="token number">0.0162886</span>   <span class="token number">0.9483853</span> <span class="token punctuation">]</span><br> <span class="token punctuation">[</span> <span class="token number">0.4709251</span>  <span class="token operator">-</span><span class="token number">0.18713968</span>  <span class="token number">0.8347026</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span></p><p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span><br> <span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span></p><p>tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">12</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int32<span class="token punctuation">)</span><br><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">12</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">]</span></p><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4334&quot;}"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li></ul></pre> <hr> <h1><a name="t7"></a><a id="_388"></a>四.总结</h1> <p>最后希望基础性文章对您有所帮助，作者也是这个领域的菜鸟一枚，希望与您共同进步，后续会继续深入分享Python人工智能系列，如果喜欢点个赞评论，共勉~</p> <p><img src="https://img-blog.csdnimg.cn/20191128170443362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Vhc3Rtb3VudA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" width="300" height="400"></p> </div></div>]]></content>
      
      
      
        <tags>
            
            <tag> TensorFLow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Unreal Engine</title>
      <link href="/2023/03/01/Unreal%20Engine%20Basics/"/>
      <url>/2023/03/01/Unreal%20Engine%20Basics/</url>
      
        <content type="html"><![CDATA[<h1>【学习笔记】Unreal（虚幻）4引擎入门（一）</h1><hr> <p style="text-indent:33px;"><strong>今天是第一篇，从安装、启动到第一个教学工程。</strong></p> <h2><a name="t0"></a>安装</h2> <p style="text-indent:33px;">虚幻引擎安装很便利，使用Epic游戏平台即可下载安装。得益于腾讯注资了Epic，国内服务器下载速度杠杠快，虚幻4的4.25.3版本大小11GB左右，我的下载速度基本上在5-6M/S。</p> <p style="text-indent:33px;">下图就是Epic的游戏平台，左侧点击虚幻引擎，下载安装即可，下载完右上角黄色按钮启动，或者桌面快捷方式启动。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/2020082622502384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <h2><a name="t1"></a>启动和第一个教学工程</h2> <p style="text-indent:33px;">启动虚幻引擎后，会出现如下图的界面。可以按照自己的需要选择不同的大类。跟随虚幻4的<a href="https://docs.unrealengine.com/zh-CN/Engine/QuickStart/index.html">官方教程</a>，这里选择游戏大类。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/2020082622532020.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">随后便弹出项目浏览器界面，如下图所示。按照教程的指导，选择蓝图（目前的理解类似于使用模板，而不是C++代码来构建，适合没有编程经验的开发者直接上手）和包含初学者内容包（这里包含了一些设定好的家具、素材贴图等）。同时选择项目保存地址和项目名称。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826225615477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">点击创建项目后，便是漫长的加载过程。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826225842959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">加载完成后，会弹出初始界面：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826225918748.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">初始界面中已经有了一个样例场景，就是上图的座椅和地面。我们需要从头来过，那就点击上图左上角的文件，创建新关卡，选择空白关卡即可：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230058511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">空白关卡建立好后，界面中的视口（就是显示座椅板凳的地方会变成漆黑一片），就需要我们添加所需的部件。比如添加一个正方形，通过调整它的角度及宽高比，让它变成地面部件：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230339526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230404407.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">同理，有了地面，添加光源可以加入点光源或者定向光源（我的理解类似于太阳光），以及不同的小部件，如椅子桌子等。然后通过点击单个物品可以旋转（E），平移（W）和缩放（R），将它们放置到我们需要的地方。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230852344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">而视口中的快捷操作如下图：</p> <p style="text-indent:33px;"><img alt="" height="773" src="https://img-blog.csdnimg.cn/20200826230825138.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70" width="685"></p> <p style="text-indent:33px;">按照教程布置完成后，我们有了如下的场景，一个漏风的破房：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230953590.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">随后通过添加贴图，玩家出生点，调整光源等亿点点的细节后，就可以开始Build这个工程了，Build过程中会将静态的未经烘焙的光源进行实时运算：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826231112144.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">最后点击运行，就可以通过WSAD和鼠标在构建的场景里面游览了：</p> <p style="text-align:center;"><img alt="" height="461" src="https://img-blog.csdnimg.cn/20200826231504406.gif" width="817"></p> <p style="text-indent:33px;">最后，感叹虚幻引擎的强大，而且虚幻5马上要和大家见了。可以用第九艺术实现自己的梦，真的太美妙！</p>                <div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/yourgreatfather/article/details/108249291&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>        ](<div id="article_content" class="article_content clearfix">        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-25cebea3f9.css">                <div id="content_views" class="htmledit_views">                    <p style="text-indent:33px;">刚入职新工作一个多月，目前不算太忙，晚上在家浪费时间心里难安。介于本人热爱游戏，最近闲来无事自学虚幻4引擎，若能坚持下去，希望有朝一日可以自己做出一款游戏（想吃屁）。</p> <hr> <p style="text-indent:33px;"><strong>今天是第一篇，从安装、启动到第一个教学工程。</strong></p> <h2><a name="t0"></a>安装</h2> <p style="text-indent:33px;">虚幻引擎安装很便利，使用Epic游戏平台即可下载安装。得益于腾讯注资了Epic，国内服务器下载速度杠杠快，虚幻4的4.25.3版本大小11GB左右，我的下载速度基本上在5-6M/S。</p> <p style="text-indent:33px;">下图就是Epic的游戏平台，左侧点击虚幻引擎，下载安装即可，下载完右上角黄色按钮启动，或者桌面快捷方式启动。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/2020082622502384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <h2><a name="t1"></a>启动和第一个教学工程</h2> <p style="text-indent:33px;">启动虚幻引擎后，会出现如下图的界面。可以按照自己的需要选择不同的大类。跟随虚幻4的<a href="https://docs.unrealengine.com/zh-CN/Engine/QuickStart/index.html">官方教程</a>，这里选择游戏大类。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/2020082622532020.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">随后便弹出项目浏览器界面，如下图所示。按照教程的指导，选择蓝图（目前的理解类似于使用模板，而不是C++代码来构建，适合没有编程经验的开发者直接上手）和包含初学者内容包（这里包含了一些设定好的家具、素材贴图等）。同时选择项目保存地址和项目名称。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826225615477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">点击创建项目后，便是漫长的加载过程。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826225842959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">加载完成后，会弹出初始界面：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826225918748.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">初始界面中已经有了一个样例场景，就是上图的座椅和地面。我们需要从头来过，那就点击上图左上角的文件，创建新关卡，选择空白关卡即可：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230058511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">空白关卡建立好后，界面中的视口（就是显示座椅板凳的地方会变成漆黑一片），就需要我们添加所需的部件。比如添加一个正方形，通过调整它的角度及宽高比，让它变成地面部件：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230339526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230404407.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">同理，有了地面，添加光源可以加入点光源或者定向光源（我的理解类似于太阳光），以及不同的小部件，如椅子桌子等。然后通过点击单个物品可以旋转（E），平移（W）和缩放（R），将它们放置到我们需要的地方。</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230852344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">而视口中的快捷操作如下图：</p> <p style="text-indent:33px;"><img alt="" height="773" src="https://img-blog.csdnimg.cn/20200826230825138.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70" width="685"></p> <p style="text-indent:33px;">按照教程布置完成后，我们有了如下的场景，一个漏风的破房：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826230953590.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">随后通过添加贴图，玩家出生点，调整光源等亿点点的细节后，就可以开始Build这个工程了，Build过程中会将静态的未经烘焙的光源进行实时运算：</p> <p style="text-align:center;"><img alt="" src="https://img-blog.csdnimg.cn/20200826231112144.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdXJncmVhdGZhdGhlcg==,size_16,color_FFFFFF,t_70"></p> <p style="text-indent:33px;">最后点击运行，就可以通过WSAD和鼠标在构建的场景里面游览了：</p> <p style="text-align:center;"><img alt="" height="461" src="https://img-blog.csdnimg.cn/20200826231504406.gif" width="817"></p> <p style="text-indent:33px;">最后，感叹虚幻引擎的强大，而且虚幻5马上要和大家见了。可以用第九艺术实现自己的梦，真的太美妙！</p>                </div><div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/yourgreatfather/article/details/108249291&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>        </div>)]]></content>
      
      
      
        <tags>
            
            <tag> UE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue3开发教程</title>
      <link href="/2023/02/07/Vue3%E5%BC%80%E5%8F%91%E6%95%99%E7%A8%8B/"/>
      <url>/2023/02/07/Vue3%E5%BC%80%E5%8F%91%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title=" 前言"></a> 前言</h1><p>本文是笔者学习vue前端技术过程的总结，其中包括vue开发需要了解的相关技术如：node、ES6、TypeScript、vite、ElementUI。以vue作为主线来介绍相关技术，最后通过一个典型的前端应用来体会vue的开发。希望笔者的内容能帮助将要学习vue的同学，由于本人对前端技术了解有限，如有理解不到位的地方希望各路大神给予意见。同时也欢迎大家的留言与交流。</p><hr><blockquote><p>提示：本文中的技术关键字可以链接到该技术的官网站</p></blockquote><h1 id="一、学习Vue前需要了解的内容"><a href="#一、学习Vue前需要了解的内容" class="headerlink" title="一、学习Vue前需要了解的内容"></a>一、学习Vue前需要了解的内容</h1><h2 id="web基础知识"><a href="#web基础知识" class="headerlink" title="web基础知识"></a>web基础知识</h2><p><a href="https://www.w3school.com.cn/html/index.asp" title="html">html</a>、<a href="https://www.w3school.com.cn/css/index.asp" title="css">css</a>、<a href="https://www.w3school.com.cn/js/index.asp" title="javascript">javascript</a></p><h2 id="Node-js"><a href="#Node-js" class="headerlink" title="Node.js"></a>Node.js</h2><p>官方的描述“<a href="https://nodejs.org/en/" title="Node.js">Node.js</a> 是一个基于 Chrome V8 引擎的 JavaScript 运行时。”笔这认为就是一种编程语言的运行平台。类似java语言中的JVM。<a href="http://nodejs.cn/" title="中文网站地址">中文网站地址</a></p><h2 id="NPM"><a href="#NPM" class="headerlink" title="NPM"></a>NPM</h2><p>npm包管理器，可用于管理node.js的开发依赖的类库。类似java开发中的maven或gradle。在<a href="https://www.npmjs.com/" title="npm">npm</a>网站可以查询各种开发资源。通过npm install 可以安装到本地。</p><pre><code>npm install vue</code></pre><h2 id="TypeScript"><a href="#TypeScript" class="headerlink" title="TypeScript"></a>TypeScript</h2><p>官网描述”<a href="https://www.tslang.cn/index.html" title="typescript">typescript</a>是javascript类型的超集，它可以编译成纯javascript。”笔者人为javascript的的语法typescript都支持，但是typescript功能更加强大。下面介绍一下开发中比较常用的代码，更详细请参考<a href="https://www.tslang.cn/docs/home.html" title="用户指南">用户指南</a>。<br><strong>变量</strong><br>格式：&lt;修饰符&gt; 名称:&lt;类型&gt;</p><pre><code>let isDone: boolean = false;let decLiteral: number = 6;let name: string = "bob";let list: number[] = [1, 2, 3];</code></pre><p><strong>模块</strong></p><p><strong>导入</strong>：使用关键字 “<code>import”</code>来导入其它模块中的导出内容。</p><pre><code>//导入一个模块中的某个导出内容import { ZipCodeValidator } from "./ZipCodeValidator";let myValidator = new ZipCodeValidator(); //对导入内容重命名import { ZipCodeValidator as ZCV } from "./ZipCodeValidator";let myValidator = new ZCV(); //将整个模块导入到一个变量，并通过它来访问模块的导出部分import * as validator from "./ZipCodeValidator";let myValidator = new validator.ZipCodeValidator();</code></pre><p><strong>导出</strong>：任何声明（比如变量，函数，类，类型别名或接口）都能够通过添加<code>export</code>关键字来导出。主要有以下三种导出方式：导出声明，语句导出，</p><pre><code>//1.导出声明 //导出定义的接口export interface StringValidator {    isAcceptable(s: string): boolean;} //2.语句导出 //导出类与设置导出别名class ZipCodeValidator implements StringValidator {    isAcceptable(s: string) {        return s.length === 5 &amp;&amp; numberRegexp.test(s);    }}export { ZipCodeValidator };export { ZipCodeValidator as mainValidator }; //3.重新导出 //导出原先的验证器但做了重命名export {ZipCodeValidator as RegExpBasedZipCodeValidator} from "./ZipCodeValidator"; //导出LettersOnlyValidator所有内容export * from "./LettersOnlyValidator"; </code></pre><p><strong>默认导出</strong></p><pre><code>//JQuery.d.ts//导出默认$为JQuerydeclare let $: JQuery;export default $;  //App.ts//导入默认的导出import $ from "JQuery";$("button.continue").html( "Next Step..." );</code></pre><h2 id="Vite"><a href="#Vite" class="headerlink" title="Vite"></a>Vite</h2><p><a href="https://vitejs.cn/" title="vite">vite</a>是一个前端构建工具，可在node环境运行。适合vue程序的开发，工程目录及文件命运要符合vite的要求。可以通过vite init创建一个空白的vue项目作为基础进行开发。</p><pre><code># npm 6.xnpm init vite@latest my-vue-app --template vue # npm 7+, 需要额外的双横线：npm init vite@latest my-vue-app -- --template vue</code></pre><h2 id="Element-Plus"><a href="#Element-Plus" class="headerlink" title="Element Plus"></a>Element Plus</h2><p><a href="https://element-plus.org/zh-CN/#/zh-CN" title="Element Plus">Element Plus</a> 是基于Vue3开发的UI框架，其中包括大量封装好的组件可直接使用，使项目开发更容易。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue的路由配置（Vue2和Vue3的路由配置）</title>
      <link href="/2023/01/04/Vue%E7%9A%84%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE%EF%BC%88Vue2%E5%92%8CVue3%E7%9A%84%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE%EF%BC%89/"/>
      <url>/2023/01/04/Vue%E7%9A%84%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE%EF%BC%88Vue2%E5%92%8CVue3%E7%9A%84%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AE%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="系列文章目录"><a href="#系列文章目录" class="headerlink" title="系列文章目录"></a>系列文章目录</h1><p><code>Tips：使用Vue3开发项目已经有一段时间了，关于Vue2的路由是如何一步一步搭建的都快要忘记了，今天写着篇文章主要就是回顾一下，在Vue2和Vue3中我们是如何一步一步的配置路由的。</code></p><hr><p><code>提示：最好的进步就是有闲暇时间就敲一敲代码！！！！！</code></p><h3 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h3><ul><li><a href="#%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95">系列文章目录</a><ul><li><a href="#%E6%96%87%E7%AB%A0%E7%9B%AE%E5%BD%95">文章目录</a></li></ul></li><li><a href="#%E4%B8%80%E8%B7%AF%E7%94%B1%E6%98%AF%E4%BB%80%E4%B9%88">一、路由是什么？</a></li><li><a href="#%E4%BA%8Cvue2%E4%B8%AD%E8%B7%AF%E7%94%B1%E7%9A%84%E5%88%9B%E5%BB%BA%E6%AD%A5%E9%AA%A4">二、Vue2中路由的创建步骤</a><ul><li><a href="#1%E5%AE%89%E8%A3%85%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%B7%AF%E7%94%B1%E7%89%88%E6%9C%AC%E8%BF%99%E9%87%8C%E6%88%91%E8%B8%A9%E5%9D%91%E4%BA%86">1.安装正确的路由版本（这里我踩坑了）</a></li><li><a href="#2vue2%E4%B8%AD%E9%85%8D%E7%BD%AE%E8%B7%AF%E7%94%B1%E7%9A%84%E6%AD%A5%E9%AA%A4">2.vue2中配置路由的步骤</a></li></ul></li><li><a href="#%E4%B8%89vue3%E4%B8%AD%E8%B7%AF%E7%94%B1%E7%9A%84%E5%88%9B%E5%BB%BA%E6%AD%A5%E9%AA%A4">三、Vue3中路由的创建步骤</a><ul><li><a href="#1%E6%AD%A5%E9%AA%A4%E5%A6%82%E4%B8%8B">1.步骤如下</a></li></ul></li></ul><hr><h1 id="一、路由是什么？"><a href="#一、路由是什么？" class="headerlink" title="一、路由是什么？"></a>一、路由是什么？</h1><blockquote><p><code>Vue</code>中的路由就是.<code>SPA（single page application 单页应用程序）</code> 的路径管理器。</p><p><code>vue-router</code>是Vue.js官方的路由插件，用于构建单页面应用。vue的单页面应用是基于<code>路由</code>和<code>组件</code>的，<code>设定访问路径，并将路径和组件映射起来</code>。在<a href="https://so.csdn.net/so/search?q=vue-router&amp;spm=1001.2101.3001.7020">vue-router</a>单页面应用中，<code>路径之间的切换，就是组件的切换</code>。路由模块的本质就是建立起url和页面之间的映射关系。</p></blockquote><h1 id="二、Vue2中路由的创建步骤"><a href="#二、Vue2中路由的创建步骤" class="headerlink" title="二、Vue2中路由的创建步骤"></a>二、<a href="https://so.csdn.net/so/search?q=Vue2&amp;spm=1001.2101.3001.7020">Vue2</a>中路由的创建步骤</h1><h2 id="1-安装正确的路由版本（这里我踩坑了）"><a href="#1-安装正确的路由版本（这里我踩坑了）" class="headerlink" title="1.安装正确的路由版本（这里我踩坑了）"></a>1.安装正确的路由版本（这里我踩坑了）</h2><p><code>1.首先安装vue-router的时候需要确定版本。 Vue2.0采用的 vue-router 版本为 @^3.5.1</code></p><pre><code>npm i vue-router@^3.5.1 -s  // Vue2安装的方式</code></pre><p><code>2.直接 npm i vue-router -s 这种方式安装会安装最新版本（适用于Vue3）</code></p><pre><code>npm i vue-router -s  //Vue3安装的方式</code></pre><h2 id="2-vue2中配置路由的步骤"><a href="#2-vue2中配置路由的步骤" class="headerlink" title="2.vue2中配置路由的步骤"></a>2.vue2中配置路由的步骤</h2><blockquote><h3 id="步骤如下："><a href="#步骤如下：" class="headerlink" title="步骤如下："></a>步骤如下：</h3></blockquote><p><code>1.安装 vue-router@3.5.1</code><br><code>2.创建 router文件夹 并创建 index.js</code><br><code>3.引入VueRouter 和 Vue</code><br><code>4.Vue.use(VueRouter)</code><br><code>5.创建VueRouter实例： const router = new VueRouter（{ routes}）</code><br><code>6.配置routes （结构如下图所示）</code><br><code>7.导出router</code><br><code>8. 在main.js中导入刚才的 router</code><br><code>9.注册router</code><br><code>10.创建 router-link 和 router-view</code></p><blockquote><p><code>路由文件代码：</code></p></blockquote><pre><code>//1.导入VueRouterimport Vue from "vue";import VueRouter from 'vue-router'import HelloWord from "../components/HelloWorld.vue";//2.使用路由Vue.use(VueRouter);//3.创建VueRouter的实例const router = new VueRouter({    //tips:不想要 #（锚点）就添加下面代码     mode:'history',     //4.配置路由的path和组件    routes :[        {          path: "/",          name:'home',          component: HelloWord,        },        {          path: "/about",          name:'anout',          component: () =&gt; import("../components/About.vue"),        },      ]})//5.导入路由实例export default router</code></pre><p>​    </p><blockquote><p><code>入口文件代码：</code></p></blockquote><pre><code>import Vue from 'vue'import App from './App.vue'//6.引入导出的路由import router from './router/index'Vue.config.productionTip = falsenew Vue({  //7.注册路由  router,  render: h =&gt; h(App),}).$mount('#app')</code></pre><p>​    </p><h1 id="三、Vue3中路由的创建步骤"><a href="#三、Vue3中路由的创建步骤" class="headerlink" title="三、Vue3中路由的创建步骤"></a>三、<a href="https://so.csdn.net/so/search?q=Vue3&amp;spm=1001.2101.3001.7020">Vue3</a>中路由的创建步骤</h1><h2 id="1-步骤如下"><a href="#1-步骤如下" class="headerlink" title="1.步骤如下"></a>1.步骤如下</h2><p><code>1. 创建对应的文件夹router 创建 index.js文件，</code><br><code>2. 安装vue-router （vue3.0直接安装就行）</code><br><code>3. 导入createRouter 和 createWebHashHistory</code><br><code>4. 配置routes</code><br><code>5. 使用createRouter注册routes和配置路由模式</code><br><code>6. 导出路由</code><br><code>7. 在main.js中 导入router ，并通过链式 .use(router) 注册</code></p><blockquote><p><code>路由文件代码：</code></p></blockquote><pre><code>import { createRouter, createWebHashHistory } from "vue-router"; import HelloWord from '../components/HelloWorld.vue'const router = createRouter({  history: createWebHashHistory(),  routes: [    {      path: "/",      component:HelloWord    },    {        path:"/about",        component:() =&gt; import("../components/About.vue")    }  ],});export default router</code></pre><p>​    </p><blockquote><p><code>入口文件代码：</code></p></blockquote><pre><code>import { createApp } from 'vue'import App from './App.vue'import router from './router'createApp(App).use(router).mount('#app')</code></pre><p>​    </p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> Vue </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
